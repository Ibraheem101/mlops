{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ibraheem101/mlops/blob/main/foundations/Embeddings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vYuaJ95yvnXS"
      },
      "source": [
        "# Word embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NOkYk3NsvqBt"
      },
      "source": [
        "The motivation for word embeddings in natural language processing (NLP) arises from the need to represent words in a numerical format that captures their semantic and syntactic similarities. Traditional approaches in NLP, such as one-hot encoding or bag-of-words representations, treat words as discrete symbols with no inherent meaning or relationship between them. However, words do possess rich contextual information and often exhibit semantic connections based on their usage in text.\n",
        "\n",
        "Word embeddings aim to address this limitation by representing words as dense vectors in a continuous vector space. The key motivation behind word embeddings is to capture the meaning and relationships between words based on their distributional properties in a given corpus. The underlying idea is that words that occur in similar contexts tend to have similar meanings.\n",
        "\n",
        "By learning word embeddings, NLP models can benefit from several advantages:\n",
        "\n",
        "* Semantic Similarity: Word embeddings capture semantic relationships between words. Words with similar meanings or concepts are represented by vectors that are closer to each other in the embedding space. For example, the vectors for \"king\" and \"queen\" would be closer to each other than to the vector for \"apple.\"\n",
        "\n",
        "* Syntactic Regularities: Word embeddings can capture syntactic regularities and analogies between words. For example, the vector difference between \"man\" and \"woman\" might be similar to the vector difference between \"king\" and \"queen,\" capturing the analogy between gendered terms.\n",
        "\n",
        "* Dimensionality Reduction: Word embeddings provide a lower-dimensional representation of words compared to one-hot encoding or bag-of-words models. This reduces the dimensionality of the input space and helps mitigate the curse of dimensionality in NLP tasks.\n",
        "\n",
        "* Generalization: Word embeddings can generalize to unseen words or rare words by leveraging the similarities learned from the training data. Models can infer similarities and relationships for words not explicitly encountered during training, which is valuable for handling out-of-vocabulary words.\n",
        "\n",
        "* Efficiency: Word embeddings reduce the computational complexity of NLP models by representing words as continuous vectors. This enables efficient processing and computation compared to sparse representations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "46XqVPhSmysu"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import json\n",
        "import math\n",
        "import nltk\n",
        "import torch\n",
        "import gensim\n",
        "import random\n",
        "import urllib\n",
        "import itertools\n",
        "import collections\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OZuNpyFHv-p7"
      },
      "source": [
        "We can learn embeddings by creating our models in PyTorch but first, we're going to use a library that specializes in embeddings and topic modeling called Gensim."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vFM9Wu9om-54",
        "outputId": "d1f2c5ee-c96c-4c44-adc6-46d5ea969af9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "nltk.download(\"punkt\")\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "lZCeq1o8xVFK"
      },
      "outputs": [],
      "source": [
        "seed = 1234"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "f5SqRRYjwFMx"
      },
      "outputs": [],
      "source": [
        "def set_seeds(seed=1234):\n",
        "    \"\"\"Set seeds for reproducibility.\"\"\"\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed) # multi-GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "drh1o9JTxSCb"
      },
      "outputs": [],
      "source": [
        "set_seeds(seed = seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RqDiCvl90hwN"
      },
      "source": [
        "### Load data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3xrDMHYvxWsJ",
        "outputId": "b8cd4e9b-4738-48bc-80d2-0ab70c7b0788"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12449 sentences\n"
          ]
        }
      ],
      "source": [
        "# Split text into sentences\n",
        "tokenizer = nltk.data.load(\"tokenizers/punkt/english.pickle\")\n",
        "book = urllib.request.urlopen(url=\"https://raw.githubusercontent.com/GokuMohandas/Made-With-ML/main/datasets/harrypotter.txt\")\n",
        "sentences = tokenizer.tokenize(str(book.read()))\n",
        "print (f\"{len(sentences)} sentences\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "HBVv7FIU0n_P",
        "outputId": "0c714ccd-de9d-4072-e6a4-83cffe5cddbc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'He seemed unable to prevent himself from glancing upward every minute or so.\\\\r\\\\n\"Yaxley.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "sentences[26]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "VQJJWEOZ0rQO"
      },
      "outputs": [],
      "source": [
        "def preprocess(text):\n",
        "\n",
        "    # lowercasing\n",
        "    text = text.lower()\n",
        "\n",
        "    # Spacing and filters\n",
        "    text = re.sub(r\"([-;;.,!?<=>])\", r\" \\1 \", text)\n",
        "    text = re.sub(\"[^A-Za-z0-9]+\", \" \", text) # remove non alphanumeric chars\n",
        "    text = re.sub(\" +\", \" \", text)  # remove multiple spaces\n",
        "    text = text.strip()\n",
        "\n",
        "    # Separate into word tokens\n",
        "    text = text.split(\" \")\n",
        "\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8cHz3ynG4VYh",
        "outputId": "baa791ff-9481-4b01-b2ef-885185510481"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Snape,\" said a high, clear voice from the head of the table.\n",
            "['snape', 'said', 'a', 'high', 'clear', 'voice', 'from', 'the', 'head', 'of', 'the', 'table']\n"
          ]
        }
      ],
      "source": [
        "print(sentences[27])\n",
        "sentences = [preprocess(sentence) for sentence in sentences]\n",
        "print(sentences[27])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfeiD7r0INaq"
      },
      "source": [
        "<details>\n",
        "    <summary>Approaches to learning embeddings</summary>\n",
        "\n",
        "1. Continuous Bag of Words (CBOW):\n",
        "In CBOW, the objective is to predict the target word based on the context words surrounding it.\n",
        "The model takes a fixed-size context window of words as input and tries to predict the target word in the middle.\n",
        "The context words are typically represented as one-hot vectors or pre-trained word embeddings.\n",
        "The model is trained using a neural network, where the context words are passed through an embedding layer, followed by a hidden layer, and finally a softmax output layer.\n",
        "The embedding layer learns the dense representations (embeddings) of the context words, which are updated during training to improve the prediction accuracy.\n",
        "The learned embeddings capture the semantic and syntactic relationships between words based on their co-occurrence patterns.\n",
        "\n",
        "2. Skip-gram:\n",
        "In skip-gram, the objective is to predict the context words given a target word.\n",
        "The model takes a target word as input and tries to predict the surrounding context words.\n",
        "Similar to CBOW, the context words can be represented as one-hot vectors or pre-trained embeddings.\n",
        "The model architecture consists of an embedding layer followed by a hidden layer and a softmax output layer.\n",
        "During training, the model adjusts the embeddings to maximize the probability of predicting the correct context words.\n",
        "The skip-gram approach is useful when we want to focus on rare words and capture more fine-grained relationships between words.\n",
        "\n",
        "3. Language Modeling (LM):\n",
        "Language modeling involves predicting the next word in a sequence of words given the previous words.\n",
        "The objective of LM is to learn the probability distribution of words in a language.\n",
        "The model takes a sequence of words as input and tries to predict the next word.\n",
        "It typically uses recurrent neural network (RNN) architectures, such as LSTM or GRU, to capture the sequential dependencies between words.\n",
        "The embeddings are learned as part of the training process, where the model updates the embeddings based on the predicted probabilities.\n",
        "Language models can be trained on large text corpora and can capture the contextual relationships between words.\n",
        "These approaches learn word embeddings by training neural network models on large amounts of text data. By considering the context of words, they capture the semantic and syntactic relationships, allowing words with similar meanings or usage to have similar embeddings. The resulting embeddings can then be used in various NLP tasks such as sentiment analysis, machine translation, and text generation.\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wJvvr4P9SyHM"
      },
      "source": [
        "### Word2vec\n",
        "[Understand Word2vec](https://mccormickml.com/2016/04/19/word2vec-tutorial-the-skip-gram-model/)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "PPzUkEzKP-kA"
      },
      "outputs": [],
      "source": [
        "from gensim.models import KeyedVectors\n",
        "from gensim.models import Word2Vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "wX3gYFXDQQEA"
      },
      "outputs": [],
      "source": [
        "embedding_dim = 100\n",
        "window = 5\n",
        "min_count = 3 # Ignores all words with total frequency lower than this\n",
        "skip_gram = 1 # 0 = CBOW\n",
        "negative_sampling = 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GUJYECpHVz25",
        "outputId": "2a5a8282-a0bc-4f7c-ca9f-94c9f347d2d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word2Vec<vocab=4937, vector_size=100, alpha=0.025>\n"
          ]
        }
      ],
      "source": [
        "# Super fast because of optimized C code under the hood\n",
        "w2v = Word2Vec(\n",
        "    sentences=sentences, vector_size=embedding_dim,\n",
        "    window=window, min_count=min_count,\n",
        "    sg=skip_gram, negative=negative_sampling)\n",
        "print(w2v)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HcdJuyYsWB-8",
        "outputId": "0065c08f-6ab6-4e1e-acee-61adf74e1d54"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([ 0.05554148,  0.51449263,  0.02647996, -0.00736882,  0.2349285 ,\n",
              "        -0.40939453,  0.2834695 ,  0.31534404, -0.76638186, -0.15783367,\n",
              "        -0.07916379, -0.1458145 , -0.04332679, -0.03518606, -0.14897653,\n",
              "         0.03334299,  0.4691548 , -0.15601353, -0.31418338, -0.34821525,\n",
              "        -0.25019428,  0.28169018,  0.26391193, -0.5085285 ,  0.02704121,\n",
              "        -0.04683833, -0.7389701 ,  0.08067881, -0.18744688, -0.14420679,\n",
              "         0.2577306 ,  0.17539772, -0.0375921 , -0.08126716, -0.13365084,\n",
              "        -0.01302763,  0.00153566, -0.04877523,  0.1027067 , -0.07905056,\n",
              "        -0.24179678, -0.05977676,  0.003861  ,  0.3214272 ,  0.19556916,\n",
              "        -0.23822756,  0.02331826, -0.12167119, -0.18695211, -0.04624409,\n",
              "         0.14287955,  0.12043853, -0.07325423,  0.19841047, -0.30535713,\n",
              "        -0.48660335,  0.24522428, -0.26716396, -0.27490684,  0.06907767,\n",
              "         0.16472767, -0.06080765,  0.3233195 ,  0.10316559, -0.23501824,\n",
              "         0.12153216,  0.04402173, -0.09647799, -0.08365646, -0.4226225 ,\n",
              "        -0.01499807,  0.37829623,  0.30879018,  0.10108231,  0.21007742,\n",
              "        -0.00304343, -0.06690993,  0.4468201 , -0.1774869 , -0.18845987,\n",
              "        -0.20334326, -0.00344231, -0.06235879,  0.03778439,  0.11180566,\n",
              "        -0.17479435,  0.08229259,  0.01442109,  0.1293796 , -0.17938124,\n",
              "         0.16416596,  0.49530107, -0.02184394,  0.07880308,  0.5363815 ,\n",
              "        -0.38452777, -0.00451971,  0.06602439,  0.2747535 ,  0.16086403],\n",
              "       dtype=float32),\n",
              " 100)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "# Vector for each word\n",
        "w2v.wv.get_vector(\"harry\"), len(w2v.wv.get_vector(\"harry\")) #embedding vector e"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IG0DbNm5XDOP",
        "outputId": "688978f9-183b-4264-9786-6a908a6797e8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('woman', 0.9084859490394592),\n",
              " ('witch', 0.901517391204834),\n",
              " ('wizard', 0.8934826850891113),\n",
              " ('odd', 0.8744949102401733),\n",
              " ('familiar', 0.8743767142295837)]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "# Get nearest neighbors (excluding itself)\n",
        "w2v.wv.most_similar(positive=\"man\", topn=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "7YB1mT9yXXDD"
      },
      "outputs": [],
      "source": [
        "# Saving and loading\n",
        "w2v.wv.save_word2vec_format(\"model.bin\", binary=True)\n",
        "w2v = KeyedVectors.load_word2vec_format(\"model.bin\", binary=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ELu7q8i1Zzj6"
      },
      "source": [
        "### FastText\n",
        "When a word doesn't exist in our vocabulary, there are a few approaches we can take to handle it:\n",
        "\n",
        "UNK Token:\n",
        "\n",
        "One common approach is to assign a special token, often called the \"UNK\" token, to represent out-of-vocabulary words.\n",
        "During training, if a word is encountered that is not present in the vocabulary, it is replaced with the UNK token.\n",
        "The UNK token allows the model to learn a representation for unknown words and treat them similarly during inference.\n",
        "FastText:\n",
        "\n",
        "FastText, as you mentioned, uses character-level n-grams to embed words. This technique enables it to handle rare words, misspelled words, and even words that are not present in the training corpus.\n",
        "By breaking down words into smaller subword units (character n-grams), FastText can still capture some information about the meaning of the word, even if it is unseen.\n",
        "When encountering an out-of-vocabulary word, FastText can leverage the character n-gram information to generate an embedding for the word based on the embeddings of its subword units.\n",
        "This approach can be particularly useful in scenarios where the vocabulary is limited or when dealing with morphologically rich languages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "TH_63DHYZqLe"
      },
      "outputs": [],
      "source": [
        "from gensim.models import FastText"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K6VEMPqebFZ0",
        "outputId": "b373e81e-1fb0-4709-8871-6ac8c0794df3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FastText<vocab=4937, vector_size=100, alpha=0.025>\n"
          ]
        }
      ],
      "source": [
        "# Super fast because of optimized C code under the hood\n",
        "ft = FastText(sentences=sentences, vector_size=embedding_dim,\n",
        "              window=window, min_count=min_count,\n",
        "              sg=skip_gram, negative=negative_sampling)\n",
        "print(ft)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WqzsTmlEb0hx",
        "outputId": "0e72a0dc-44f9-4772-9e96-9f19abf62b6e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The word doesn't exist in the vocabulary\n"
          ]
        }
      ],
      "source": [
        "# This word doesn't exist so the word2vec model will error out\n",
        "try:\n",
        "    w2v.most_similar(positive=\"scarring\", topn=5)\n",
        "except KeyError:\n",
        "    print(\"The word doesn't exist in the vocabulary\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AFuEx4qBbgrG",
        "outputId": "83083f09-774d-4238-e4b5-9e0dcf4188f4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('swimming', 0.9929739236831665),\n",
              " ('dabbing', 0.9921905398368835),\n",
              " ('howling', 0.9920710921287537),\n",
              " ('quivering', 0.9915287494659424),\n",
              " ('muffling', 0.9915011525154114)]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "# FastText will use n-grams to embed an OOV word\n",
        "ft.wv.most_similar(positive=\"scarring\", topn=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "Y7Alz9ctbxVn"
      },
      "outputs": [],
      "source": [
        "# Save and loading\n",
        "ft.wv.save(\"model.bin\")\n",
        "ft = KeyedVectors.load(\"model.bin\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_Hk-_56coLN",
        "outputId": "aca7f873-706e-4987-f7d0-ed698296e16e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('swimming', 0.9929739236831665),\n",
              " ('dabbing', 0.9921905398368835),\n",
              " ('howling', 0.9920710921287537),\n",
              " ('quivering', 0.9915287494659424),\n",
              " ('muffling', 0.9915011525154114)]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "ft.most_similar(positive=\"scarring\", topn=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YLhWTib8vfwl"
      },
      "source": [
        "### GloVe\n",
        "GloVe (Global Vectors for Word Representation) is an unsupervised learning algorithm for generating word embeddings. It constructs a co-occurrence matrix from a large corpus of text, initializes word vectors, defines an objective function based on co-occurrence statistics, and optimizes the word vectors to capture semantic relationships. The resulting word embeddings are dense vector representations that capture similarities between words. GloVe leverages global statistical information and performs well in various NLP tasks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "sPE2Gm6Qcqdi"
      },
      "outputs": [],
      "source": [
        "from io import BytesIO\n",
        "from zipfile import ZipFile\n",
        "from urllib.request import urlopen\n",
        "from sklearn.decomposition import PCA\n",
        "from gensim.scripts.glove2word2vec import glove2word2vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "Z_NO3aTowNMI"
      },
      "outputs": [],
      "source": [
        "def plot_embeddings(words, embeddings, pca_results):\n",
        "    for word in words:\n",
        "        index = embeddings.index_to_key.index(word)\n",
        "        plt.scatter(pca_results[index, 0], pca_results[index, 1])\n",
        "        plt.annotate(word, xy=(pca_results[index, 0], pca_results[index, 1]))\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E2swLUKuxdK3"
      },
      "source": [
        "<details>\n",
        "    <summary>Explanation</summary>\n",
        "    \n",
        "The function plot_embeddings takes three arguments: words, embeddings, and pca_results. Here's a breakdown of what the function does:\n",
        "It iterates over each word in the words list.\n",
        "For each word, it retrieves the corresponding index in the embeddings object using embeddings.index2word.index(word).\n",
        "It plots a scatter point on a 2D plot using the x and y coordinates from pca_results.\n",
        "It annotates the scatter point with the word using plt.annotate.\n",
        "Finally, it displays the plot using plt.show().\n",
        "The purpose of this function is to visualize word embeddings in a 2D space using PCA (Principal Component Analysis) results. It plots the words as scatter points and annotates each point with its corresponding word. The embeddings object represents a collection of word embeddings, and pca_results contains the PCA-transformed coordinates for each embedding. The words list specifies which words to visualize.\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FghfmFsO0w8s"
      },
      "source": [
        "### Load"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dvyM2Cmrm62j",
        "outputId": "1cefc415-c1e7-4b35-8afa-cb70b153670e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: 'content'\n",
            "/content\n"
          ]
        }
      ],
      "source": [
        "cd content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "lUCilc27zYSP"
      },
      "outputs": [],
      "source": [
        "cp kaggle.json ~/.kaggle/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "dDx78yI1zxs6"
      },
      "outputs": [],
      "source": [
        "! chmod 600 /root/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TLhIG3dAydCW",
        "outputId": "acb698b2-8ad9-46a7-8c47-0c3468f18a36"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading glove6b.zip to /content\n",
            " 99% 835M/844M [00:10<00:00, 78.6MB/s]\n",
            "100% 844M/844M [00:10<00:00, 83.7MB/s]\n"
          ]
        }
      ],
      "source": [
        "! kaggle datasets download -d anindya2906/glove6b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "300lyFGU0zL-"
      },
      "outputs": [],
      "source": [
        "# Unzip the file (may take ~3-5 minutes)\n",
        "# Specify the path to the zip file\n",
        "zip_path = \"../content/glove6b.zip\"\n",
        "\n",
        "# Open the zip file\n",
        "with ZipFile(zip_path, 'r') as zip_ref:\n",
        "    # Extract all the contents of the zip file\n",
        "    zip_ref.extractall(\"../content/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "u8_-efhTyCF3"
      },
      "outputs": [],
      "source": [
        "# Write embeddings to file\n",
        "embeddings_file = \"glove.6B.{0}d.txt\".format(embedding_dim)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "Kx1Wa8i72GEo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "593a03c7-2a07-41a4-d65a-e8b5fa28969b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "word: the\n",
            "embedding:\n",
            "[-0.038194 -0.24487   0.72812  -0.39961   0.083172  0.043953 -0.39141\n",
            "  0.3344   -0.57545   0.087459  0.28787  -0.06731   0.30906  -0.26384\n",
            " -0.13231  -0.20757   0.33395  -0.33848  -0.31743  -0.48336   0.1464\n",
            " -0.37304   0.34577   0.052041  0.44946  -0.46971   0.02628  -0.54155\n",
            " -0.15518  -0.14107  -0.039722  0.28277   0.14393   0.23464  -0.31021\n",
            "  0.086173  0.20397   0.52624   0.17164  -0.082378 -0.71787  -0.41531\n",
            "  0.20335  -0.12763   0.41367   0.55187   0.57908  -0.33477  -0.36559\n",
            " -0.54857  -0.062892  0.26584   0.30205   0.99775  -0.80481  -3.0243\n",
            "  0.01254  -0.36942   2.2167    0.72201  -0.24978   0.92136   0.034514\n",
            "  0.46745   1.1079   -0.19358  -0.074575  0.23353  -0.052062 -0.22044\n",
            "  0.057162 -0.15806  -0.30798  -0.41625   0.37972   0.15006  -0.53212\n",
            " -0.2055   -1.2526    0.071624  0.70565   0.49744  -0.42063   0.26148\n",
            " -1.538    -0.30223  -0.073438 -0.28312   0.37104  -0.25217   0.016215\n",
            " -0.017099 -0.38984   0.87424  -0.72569  -0.51058  -0.52028  -0.1459\n",
            "  0.8278    0.27062 ]\n",
            "embedding dim: 100\n"
          ]
        }
      ],
      "source": [
        "# Preview of the GloVe embeddings file\n",
        "with open(embeddings_file, \"r\") as fp:\n",
        "    line = next(fp)\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    embedding = np.asarray(values[1:], dtype='float32')\n",
        "    print (f\"word: {word}\")\n",
        "    print (f\"embedding:\\n{embedding}\")\n",
        "    print (f\"embedding dim: {len(embedding)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "4vXava8c2YMS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5cdf4cc2-3ca9-44cb-94ef-5322d5a16dbb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-31-b004bd08d681>:3: DeprecationWarning: Call to deprecated `glove2word2vec` (KeyedVectors.load_word2vec_format(.., binary=False, no_header=True) loads GLoVE text vectors.).\n",
            "  glove2word2vec(embeddings_file, word2vec_output_file)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(400000, 100)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "# Save GloVe embeddings to local directory in word2vec format\n",
        "word2vec_output_file = \"{0}.word2vec\".format(embeddings_file)\n",
        "glove2word2vec(embeddings_file, word2vec_output_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "vPE5Smik21WF"
      },
      "outputs": [],
      "source": [
        "# Load embeddings (may take a minute)\n",
        "glove = KeyedVectors.load_word2vec_format(word2vec_output_file, binary=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "vhk3waAq3che",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b16b8e11-b35e-40e4-e026-45cb9d33c864"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('queen', 0.7698540687561035),\n",
              " ('monarch', 0.6843381524085999),\n",
              " ('throne', 0.6755736470222473),\n",
              " ('daughter', 0.6594556570053101),\n",
              " ('princess', 0.6520534157752991)]"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "# (king - man) + woman = ?\n",
        "# king - man = ? -  woman\n",
        "glove.most_similar(positive=[\"woman\", \"king\"], negative=[\"man\"], topn=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "b-Kk8Z7K3zal",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f508b565-d928-4b60-94e4-954ce0492ecc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('girl', 0.9095936417579651),\n",
              " ('mother', 0.7666921019554138),\n",
              " ('child', 0.7420270442962646),\n",
              " ('pregnant', 0.7282999157905579),\n",
              " ('girls', 0.7268646359443665)]"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "glove.most_similar(positive=[\"woman\", \"boy\"], negative=[\"man\"], topn=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "0wIXVSfb342R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d9a7e6e-e393-4cb9-ab9e-019e8d9c175f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('yeah', 0.8196864128112793),\n",
              " ('gonna', 0.7466485500335693),\n",
              " ('ok', 0.74472576379776),\n",
              " ('hello', 0.7171452045440674),\n",
              " ('`', 0.7170859575271606)]"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "# Get nearest neighbors (excluding itself)\n",
        "glove.most_similar(positive=\"hey\", topn=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "XN7yEO0zqogs"
      },
      "outputs": [],
      "source": [
        "# Reduce dimensionality for plotting\n",
        "X = np.array([glove.get_vector(word) for word in glove.index_to_key])\n",
        "pca = PCA(n_components=2)\n",
        "pca_results = pca.fit_transform(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "kP5bZCFcrjxE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "outputId": "7a676d80-3fa9-4ab7-96e0-a22220776075"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Visualize\n",
        "plot_embeddings(\n",
        "    words=[\"king\", \"queen\", \"man\", \"woman\"], embeddings=glove,\n",
        "    pca_results=pca_results)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "A6BaNSPNvGGK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6c920b3-e412-4eb6-eb67-ad9d3a30030e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('nurse', 0.7735227942466736),\n",
              " ('physician', 0.7189430594444275),\n",
              " ('doctors', 0.6824328303337097),\n",
              " ('patient', 0.6750683188438416),\n",
              " ('dentist', 0.6726033091545105)]"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "# Bias in embeddings\n",
        "glove.most_similar(positive=[\"woman\", \"doctor\"], negative=[\"man\"], topn=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "nx5oLe-xworL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7191277-22f0-46b1-9183-567eeccd6241"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ],
      "source": [
        "# Set device\n",
        "cuda = True\n",
        "device = torch.device(\"cuda\" if (\n",
        "    torch.cuda.is_available() and cuda) else \"cpu\")\n",
        "torch.set_default_tensor_type(\"torch.FloatTensor\")\n",
        "if device.type == \"cuda\":\n",
        "    torch.set_default_tensor_type(\"torch.cuda.FloatTensor\")\n",
        "print (device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "49-lIYWvxkob",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "95a337fa-a1e2-46f5-9f85-e0d7cbabb224"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               title  category\n",
              "0               O #39;Hare to reduce flight arrivals  Business\n",
              "1  Canceled Contract Clouds China #39;s IT Procur...  Sci/Tech\n",
              "2     Dow Jones Buying MarketWatch for \\$519 Million  Sci/Tech\n",
              "3  A sky-high Swedish farewell cake poisons 13 (AFP)     World\n",
              "4           Dodgers Continue Winter Trade Talks (AP)    Sports"
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-47ab52af-c6e3-4eda-a30c-6bb3507a453f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>O #39;Hare to reduce flight arrivals</td>\n",
              "      <td>Business</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Canceled Contract Clouds China #39;s IT Procur...</td>\n",
              "      <td>Sci/Tech</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Dow Jones Buying MarketWatch for \\$519 Million</td>\n",
              "      <td>Sci/Tech</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>A sky-high Swedish farewell cake poisons 13 (AFP)</td>\n",
              "      <td>World</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Dodgers Continue Winter Trade Talks (AP)</td>\n",
              "      <td>Sports</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-47ab52af-c6e3-4eda-a30c-6bb3507a453f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-e75d18cc-434b-45a7-8b44-6f70cd4106b2\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e75d18cc-434b-45a7-8b44-6f70cd4106b2')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-e75d18cc-434b-45a7-8b44-6f70cd4106b2 button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-47ab52af-c6e3-4eda-a30c-6bb3507a453f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-47ab52af-c6e3-4eda-a30c-6bb3507a453f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "# Load data\n",
        "url = \"https://raw.githubusercontent.com/GokuMohandas/Made-With-ML/main/datasets/news.csv\"\n",
        "df = pd.read_csv(url, header=0) # load\n",
        "df = df.sample(frac=1).reset_index(drop=True) # shuffle\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "saPudxFe0Fws"
      },
      "outputs": [],
      "source": [
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem import SnowballStemmer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "WJwpaE2a0Zmh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb893539-7214-4802-925d-e099b9f9795c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['i', 'me', 'my', 'myself', 'we']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "nltk.download(\"stopwords\")\n",
        "stop_words = stopwords.words(\"english\")\n",
        "print (stop_words[:5])\n",
        "snowball = SnowballStemmer('english')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "W8yeqQQb1eRz"
      },
      "outputs": [],
      "source": [
        "def preprocess(text, stopwords = stop_words):\n",
        "\n",
        "    # lowercasing\n",
        "    text = text.lower()\n",
        "\n",
        "    # Remove stopwords\n",
        "    pattern = re.compile(r\"\\b(\" + r\"|\".join(stopwords) + r\")\\b\\s*\")\n",
        "    text = pattern.sub(\"\", text)\n",
        "\n",
        "    # Remove words in parenthesis\n",
        "    text = re.sub(r\"\\([^)]*\\)\", \"\", text)\n",
        "\n",
        "    # Spacing and filters\n",
        "    text = re.sub(r\"([-;;.,!?<=>])\", r\" \\1 \", text)  # separate punctuation tied to words\n",
        "    text = re.sub(\"[^A-Za-z0-9]+\", \" \", text)  # remove non alphanumeric chars\n",
        "    text = re.sub(\" +\", \" \", text)  # remove multiple spaces\n",
        "    text = text.strip()\n",
        "\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "0PzTAFWN3ax8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "975aa75b-fdc8-4f81-cf10-b9fafd8e76c9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'great week nyse'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "# Sample\n",
        "text = \"Great week for the NYSE!\"\n",
        "preprocess(text=text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "DIv_yB7f4c4m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3637db40-202f-46d2-d78c-d8c834ed28ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "O #39;Hare to reduce flight arrivals\n",
            "\n",
            "39 hare reduce flight arrivals\n"
          ]
        }
      ],
      "source": [
        "# Apply to dataframe\n",
        "preprocessed_df = df.copy()\n",
        "preprocessed_df.title = preprocessed_df.title.apply(preprocess)\n",
        "print (f\"{df.title.values[0]}\\n\\n{preprocessed_df.title.values[0]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O6jbnwz08bOr"
      },
      "source": [
        "### Split data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "61NW0bdz5T2y"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "rjAInvGy8kc1"
      },
      "outputs": [],
      "source": [
        "train_size = 0.7\n",
        "val_size = 0.15\n",
        "test_size = 0.15"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "evaObaCR8rp9"
      },
      "outputs": [],
      "source": [
        "def train_val_test_split(X, y, train_size):\n",
        "    \"\"\"Split dataset into data splits.\"\"\"\n",
        "    X_train, X_, y_train, y_ = train_test_split(X, y, train_size=train_size, stratify=y)\n",
        "    X_val, X_test, y_val, y_test = train_test_split(X_, y_, train_size=0.5, stratify=y_)\n",
        "    return X_train, X_val, X_test, y_train, y_val, y_test\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "dpDnUbhT8zIb"
      },
      "outputs": [],
      "source": [
        "# Data\n",
        "X = preprocessed_df[\"title\"].values\n",
        "y = preprocessed_df[\"category\"].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "afJrS-y381vb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77b34a23-3cfb-4358-ff20-91fdfa032d52"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train: (84000,), y_train: (84000,)\n",
            "X_val: (18000,), y_val: (18000,)\n",
            "X_test: (18000,), y_test: (18000,)\n",
            "Sample point: knicks dig hole early 39 quite climb → Sports\n"
          ]
        }
      ],
      "source": [
        "# Create data splits\n",
        "X_train, X_val, X_test, y_train, y_val, y_test = train_val_test_split(\n",
        "    X=X, y=y, train_size=train_size)\n",
        "print (f\"X_train: {X_train.shape}, y_train: {y_train.shape}\")\n",
        "print (f\"X_val: {X_val.shape}, y_val: {y_val.shape}\")\n",
        "print (f\"X_test: {X_test.shape}, y_test: {y_test.shape}\")\n",
        "print (f\"Sample point: {X_train[0]} → {y_train[0]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qFI7UlqE9UJy"
      },
      "source": [
        "### Label Encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "eQV0R8yT9T4o"
      },
      "outputs": [],
      "source": [
        "from collections import OrderedDict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "id": "zL26dDBx82nI"
      },
      "outputs": [],
      "source": [
        "class LabelEncoder(object):\n",
        "    \"\"\"\n",
        "        Class to transform categorical labels into numerical values.\n",
        "\n",
        "        Attributes:\n",
        "            mapping (dict): A dictionary that maps labels to their corresponding numerical values.\n",
        "            reverse_mapping (dict): A dictionary that maps numerical values back to their original labels.\n",
        "            classes (list): A list of unique labels.\n",
        "\n",
        "        Methods:\n",
        "            fit(data): Fit the encoder to the given data by creating the mapping and reverse_mapping dictionaries.\n",
        "            encode(data): Encode the given data by replacing labels with their corresponding numerical values.\n",
        "            decode(data): Decode the given data by replacing numerical values with their original labels.\n",
        "            __len__(): Return the number of unique labels in the encoder.\n",
        "            __str__(): Return a string representation of the encoder.\n",
        "            save(fp): Save the encoder's mapping dictionary to a JSON file.\n",
        "            load(fp): Load a saved encoder from a JSON file.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    def __init__(self):\n",
        "        self.mapping = {}\n",
        "        self.reverse_mapping = {}\n",
        "        self.classes = []\n",
        "\n",
        "    def fit(self, data):\n",
        "        unique_labels = list(OrderedDict.fromkeys(data))\n",
        "        for value, label in enumerate(unique_labels):\n",
        "            self.mapping[label] = value\n",
        "            self.reverse_mapping[value] = label\n",
        "            self.classes.append(label)\n",
        "\n",
        "    def encode(self, data):\n",
        "        return [self.mapping[i] for i in data]\n",
        "\n",
        "    def decode(self, data):\n",
        "        return [self.reverse_mapping[j] for j in data]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.mapping)\n",
        "\n",
        "    def __str__(self):\n",
        "        return f\"<LabelEncoder(num_classes={len(self)})>\"\n",
        "\n",
        "    def save(self, fp):\n",
        "        with open(fp, \"w\") as fp:\n",
        "            contents = {'mapping': self.mapping}\n",
        "            json.dump(contents, fp, indent=4, sort_keys=False)\n",
        "\n",
        "    # classmethod\n",
        "    # def load(cls, fp):\n",
        "    #     with open(fp, \"r\") as fp:\n",
        "    #         kwargs = json.load(fp=fp)\n",
        "    #     return cls(**kwargs)\n",
        "\n",
        "    @classmethod\n",
        "    def load(cls, fp):\n",
        "        with open(fp, \"r\") as fp:\n",
        "            contents = json.load(fp=fp)\n",
        "        encoder = cls()\n",
        "        encoder.mapping = contents['mapping']\n",
        "        encoder.reverse_mapping = {v: k for k, v in encoder.mapping.items()}\n",
        "        encoder.classes = list(encoder.mapping.keys())\n",
        "        return encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "id": "q5sf7fkn9lRR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1862db9-f1c3-4568-81ed-01411863e1a2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Sports': 0, 'World': 1, 'Business': 2, 'Sci/Tech': 3}"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ],
      "source": [
        "# Encode\n",
        "label_encoder = LabelEncoder()\n",
        "label_encoder.fit(y_train)\n",
        "num_classes = len(label_encoder)\n",
        "label_encoder.mapping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "id": "0NvzIKOu-Z3w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0566547-194c-4a63-cbab-61227a0a0d4f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y_train[0]: Sports\n",
            "y_train[0]: 0\n"
          ]
        }
      ],
      "source": [
        "# Convert labels to tokens\n",
        "print (f\"y_train[0]: {y_train[0]}\")\n",
        "y_train_enc = label_encoder.encode(y_train)\n",
        "y_val_enc = label_encoder.encode(y_val)\n",
        "y_test_enc = label_encoder.encode(y_test)\n",
        "print (f\"y_train[0]: {y_train_enc[0]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CXjQGknF_EsG"
      },
      "source": [
        "### Class Weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "id": "q2YtWUfg-eaQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55ec8008-2d49-40ec-d384-6d0036e01681"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class weights: {0: 1.0, 1: 1.0, 2: 1.0, 3: 1.0}\n"
          ]
        }
      ],
      "source": [
        "# Calculate class weights\n",
        "class_weights = {}\n",
        "total_samples = len(y_train_enc)\n",
        "num_classes = len(np.unique(y_train_enc))\n",
        "class_samples = np.bincount(y_train_enc)\n",
        "for i in range(num_classes):\n",
        "    class_weights[i] = total_samples / (num_classes * class_samples[i])\n",
        "\n",
        "print(f\"Class weights: {class_weights}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AU4fzWtA_XSA"
      },
      "source": [
        "### Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "id": "hMGTdeau_Iaq"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "from more_itertools import take"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "id": "nmDHBDQh_Z4r"
      },
      "outputs": [],
      "source": [
        "class Tokenizer(object):\n",
        "    def __init__(self, char_level, num_tokens=None,\n",
        "                 pad_token=\"<PAD>\", oov_token=\"<UNK>\",\n",
        "                 token_to_index=None):\n",
        "        self.char_level = char_level\n",
        "        self.separator = \"\" if self.char_level else \" \"\n",
        "        if num_tokens: num_tokens -= 2 # pad + unk tokens\n",
        "        self.num_tokens = num_tokens\n",
        "        self.pad_token = pad_token\n",
        "        self.oov_token = oov_token\n",
        "        if not token_to_index:\n",
        "            token_to_index = {pad_token: 0, oov_token: 1}\n",
        "        self.token_to_index = token_to_index\n",
        "        self.index_to_token = {v: k for k, v in self.token_to_index.items()}\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.token_to_index)\n",
        "\n",
        "    def __str__(self):\n",
        "        return f\"<Tokenizer(num_tokens={len(self)})>\"\n",
        "\n",
        "    def fit_on_texts(self, texts):\n",
        "        if not self.char_level:\n",
        "            texts = [text.split(\" \") for text in texts]\n",
        "        all_tokens = [token for text in texts for token in text]\n",
        "        counts = Counter(all_tokens).most_common(self.num_tokens)\n",
        "        self.min_token_freq = counts[-1][1]\n",
        "        for token, count in counts:\n",
        "            index = len(self)\n",
        "            self.token_to_index[token] = index\n",
        "            self.index_to_token[index] = token\n",
        "        return self\n",
        "\n",
        "    def texts_to_sequences(self, texts):\n",
        "        sequences = []\n",
        "        for text in texts:\n",
        "            if not self.char_level:\n",
        "                text = text.split(\" \")\n",
        "            sequence = []\n",
        "            for token in text:\n",
        "                sequence.append(self.token_to_index.get(\n",
        "                    token, self.token_to_index[self.oov_token]))\n",
        "            sequences.append(np.asarray(sequence))\n",
        "        return sequences\n",
        "\n",
        "    def sequences_to_texts(self, sequences):\n",
        "        texts = []\n",
        "        for sequence in sequences:\n",
        "            text = []\n",
        "            for index in sequence:\n",
        "                text.append(self.index_to_token.get(index, self.oov_token))\n",
        "            texts.append(self.separator.join([token for token in text]))\n",
        "        return texts\n",
        "\n",
        "    def save(self, fp):\n",
        "        with open(fp, \"w\") as fp:\n",
        "            contents = {\n",
        "                \"char_level\": self.char_level,\n",
        "                \"oov_token\": self.oov_token,\n",
        "                \"token_to_index\": self.token_to_index\n",
        "            }\n",
        "            json.dump(contents, fp, indent=4, sort_keys=False)\n",
        "\n",
        "    @classmethod\n",
        "    def load(cls, fp):\n",
        "        with open(fp, \"r\") as fp:\n",
        "            kwargs = json.load(fp=fp)\n",
        "        return cls(**kwargs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "id": "3cxW4Lf1_dnm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab3e3678-f268-4aaf-8341-36a344e3d6b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<Tokenizer(num_tokens=500)>\n"
          ]
        }
      ],
      "source": [
        "# Tokenize\n",
        "tokenizer = Tokenizer(char_level=False, num_tokens=500)\n",
        "tokenizer.fit_on_texts(texts=X_train)\n",
        "VOCAB_SIZE = len(tokenizer)\n",
        "print (tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "id": "yTfPBMrs_gH0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c4eace3-22bb-43a3-8854-e1d62af15da6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('<PAD>', 0), ('<UNK>', 1), ('39', 2), ('b', 3), ('gt', 4)]\n",
            "least freq token's freq: 167\n"
          ]
        }
      ],
      "source": [
        "# Sample of tokens\n",
        "print (take(5, tokenizer.token_to_index.items()))\n",
        "print (f\"least freq token's freq: {tokenizer.min_token_freq}\") # use this to adjust num_tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "id": "7BkW-Vhz_j_T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bacef785-c787-42d3-a20a-124914f4a713"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text to indices:\n",
            "  (preprocessed) → <UNK> <UNK> <UNK> early 39 <UNK> <UNK>\n",
            "  (tokenized) → [  1   1   1 304   2   1   1]\n"
          ]
        }
      ],
      "source": [
        "# Convert texts to sequences of indices\n",
        "X_train_tok = tokenizer.texts_to_sequences(X_train)\n",
        "X_val_tok = tokenizer.texts_to_sequences(X_val)\n",
        "X_test_tok = tokenizer.texts_to_sequences(X_test)\n",
        "preprocessed_text = tokenizer.sequences_to_texts([X_train_tok[0]])[0]\n",
        "print (\"Text to indices:\\n\"\n",
        "    f\"  (preprocessed) → {preprocessed_text}\\n\"\n",
        "    f\"  (tokenized) → {X_train_tok[0]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z6v-faUDF1OI"
      },
      "source": [
        "### Embedding Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "id": "gn2J8Opj_n16",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b778b332-9cff-470a-e6b8-33e29bf6f21b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[5, 8, 8, 5, 1]])\n",
            "torch.Size([1, 5])\n"
          ]
        }
      ],
      "source": [
        "# Input\n",
        "vocab_size = 10\n",
        "x = torch.randint(high=vocab_size, size=(1,5))\n",
        "print (x)\n",
        "print (x.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "id": "poyHjH_gGEPp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ba1fab2-a9cc-485e-88f8-10fc5d2dda39"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([10, 100])\n"
          ]
        }
      ],
      "source": [
        "# Embedding layer\n",
        "embeddings = nn.Embedding(embedding_dim=100, num_embeddings=vocab_size)\n",
        "print (embeddings.weight.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1i5tuCHPKfTz"
      },
      "source": [
        "`print(embeddings.weight.shape)` outputs the shape of the weight matrix, which in this case will be (vocab_size, embedding_dim)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "id": "OjpXtyCyJc3N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d606fac-25e3-48d4-a660-52a1b7d1eebd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 5, 100])"
            ]
          },
          "metadata": {},
          "execution_count": 122
        }
      ],
      "source": [
        "# Embed the input\n",
        "embeddings(x).shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N631U8d6QTjT"
      },
      "source": [
        "Each token in the input is represented via embeddings (all out-of-vocabulary (OOV) tokens are given the embedding for UNK token.) In the model below, we'll see how to set these embeddings to be pretrained GloVe embeddings and how to choose whether to freeze (fixed embedding weights) those embeddings or not during training."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BBV1xNdYQnPf"
      },
      "source": [
        "### Padding\n",
        "In the context of Natural Language Processing (NLP), padding refers to the process of adding special tokens or characters to sequences in order to make them of equal length. It is necessary because many machine learning models require input data of consistent dimensions.\n",
        "\n",
        "Padding is particularly relevant when working with sequential data, such as sentences or documents, where the length of the text varies. To ensure that all sequences have the same length, shorter sequences are padded with special tokens (such as <PAD>) to match the length of the longest sequence in the dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "splkWpdFRKx9"
      },
      "source": [
        "While embedding our input tokens will create a batch of shape (N, max_seq_len, embed_dim) we only need to provide a 2D matrix (N, max_seq_len) for using embeddings with PyTorch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {
        "id": "Lm45cny5O3wQ"
      },
      "outputs": [],
      "source": [
        "def pad_sequences(sequences, max_seq_len=0):\n",
        "    \"\"\"Pad sequences to max length in sequence.\"\"\"\n",
        "    max_seq_len = max(max_seq_len, max(len(sequence) for sequence in sequences))\n",
        "    padded_sequences = np.zeros((len(sequences), max_seq_len))\n",
        "    for i, sequence in enumerate(sequences):\n",
        "        padded_sequences[i][:len(sequence)] = sequence\n",
        "    return padded_sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "id": "FNZh1js1R_hH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0cf61685-a53a-4060-eacf-21884876a976"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3, 7)\n",
            "[[  1.   1.   1. 304.   2.   1.   1.]\n",
            " [  1.   7. 219.  44. 172.   1.   0.]\n",
            " [  1.   1.   1.   1.   0.   0.   0.]]\n"
          ]
        }
      ],
      "source": [
        "# 2D sequences\n",
        "padded = pad_sequences(X_train_tok[0:3])\n",
        "print (padded.shape)\n",
        "print (padded)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {
        "id": "awSM0OSPTtfd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ffa57f92-1edd-4cfa-f88e-b09d15eacb6f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 125
        }
      ],
      "source": [
        "np.zeros((1, 5))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3JKzs2OZWcmL"
      },
      "source": [
        "### Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {
        "id": "m3l3rTTBUnCS"
      },
      "outputs": [],
      "source": [
        "filter_sizes = list(range(1, 4)) # uni, bi and tri grams"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {
        "id": "S-zLFe2xWsy-"
      },
      "outputs": [],
      "source": [
        "class Dataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, X, y, max_filter_size):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "        self.max_filter_size = max_filter_size\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.y)\n",
        "\n",
        "    def __str__(self):\n",
        "        return f\"<Dataset(N={len(self)})>\"\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        X = self.X[index]\n",
        "        y = self.y[index]\n",
        "        return [X, y]\n",
        "\n",
        "    def collate_fn(self, batch):\n",
        "        \"\"\"Processing on a batch.\"\"\"\n",
        "        # Get inputs\n",
        "        batch = np.array(batch)\n",
        "        X = batch[:, 0]\n",
        "        y = batch[:, 1]\n",
        "\n",
        "        # Pad sequences\n",
        "        X = pad_sequences(X)\n",
        "\n",
        "        # Cast\n",
        "        X = torch.LongTensor(X.astype(np.int32))\n",
        "        y = torch.LongTensor(y.astype(np.int32))\n",
        "\n",
        "        return X, y\n",
        "\n",
        "    def create_dataloader(self, batch_size, shuffle=False, drop_last=False):\n",
        "        return torch.utils.data.DataLoader(\n",
        "            dataset=self, batch_size=batch_size, collate_fn=self.collate_fn,\n",
        "            shuffle=shuffle, drop_last=drop_last, pin_memory=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {
        "id": "8civM8lpXAZv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88b8bf25-d276-46d7-bf30-a64247422436"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Datasets:\n",
            "  Train dataset:<Dataset(N=84000)>\n",
            "  Val dataset: <Dataset(N=18000)>\n",
            "  Test dataset: <Dataset(N=18000)>\n",
            "Sample point:\n",
            "  X: [  1   1   1 304   2   1   1]\n",
            "  y: 0\n"
          ]
        }
      ],
      "source": [
        "# Create datasets\n",
        "max_filter_size = max(filter_sizes)\n",
        "train_dataset = Dataset(X=X_train_tok, y=y_train_enc, max_filter_size=max_filter_size)\n",
        "val_dataset = Dataset(X=X_val_tok, y=y_val_enc, max_filter_size=max_filter_size)\n",
        "test_dataset = Dataset(X=X_test_tok, y=y_test_enc, max_filter_size=max_filter_size)\n",
        "print (\"Datasets:\\n\"\n",
        "    f\"  Train dataset:{train_dataset.__str__()}\\n\"\n",
        "    f\"  Val dataset: {val_dataset.__str__()}\\n\"\n",
        "    f\"  Test dataset: {test_dataset.__str__()}\\n\"\n",
        "    \"Sample point:\\n\"\n",
        "    f\"  X: {train_dataset[0][0]}\\n\"\n",
        "    f\"  y: {train_dataset[0][1]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {
        "id": "9TfOnHYgXEEL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7332fab0-bde8-4f4a-8f33-dd206571e6a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample batch:\n",
            "  X: [64, 14]\n",
            "  y: [64]\n",
            "Sample point:\n",
            "  X: tensor([  1,   1,   1, 304,   2,   1,   1,   0,   0,   0,   0,   0,   0,   0])\n",
            "  y: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-127-b117a8ba9edc>:21: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  batch = np.array(batch)\n"
          ]
        }
      ],
      "source": [
        "# Create dataloaders\n",
        "batch_size = 64\n",
        "train_dataloader = train_dataset.create_dataloader(batch_size=batch_size)\n",
        "val_dataloader = val_dataset.create_dataloader(batch_size=batch_size)\n",
        "test_dataloader = test_dataset.create_dataloader(batch_size=batch_size)\n",
        "batch_X, batch_y = next(iter(train_dataloader))\n",
        "print (\"Sample batch:\\n\"\n",
        "    f\"  X: {list(batch_X.size())}\\n\"\n",
        "    f\"  y: {list(batch_y.size())}\\n\"\n",
        "    \"Sample point:\\n\"\n",
        "    f\"  X: {batch_X[0]}\\n\"\n",
        "    f\"  y: {batch_y[0]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZ_enVuWa-5e"
      },
      "source": [
        "### Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SEF4vpp_aiB2"
      },
      "source": [
        "Let's visualize the model's forward pass.\n",
        "\n",
        "1. We'll first tokenize our inputs (batch_size, max_seq_len).\n",
        "2. Then we'll embed our tokenized inputs (batch_size, max_seq_len, embedding_dim).\n",
        "3. We'll apply convolution via filters (filter_size, embedding_dim, num_filters) followed by batch normalization. Our filters act as character level n-gram detectors. We have three different filter sizes (2, 3 and 4) and they will act as bi-gram, tri-gram and 4-gram feature extractors, respectively.\n",
        "4. We'll apply 1D global max pooling which will extract the most relevant information from the feature maps for making the decision.\n",
        "5. We feed the pool outputs to a fully-connected (FC) layer (with dropout).\n",
        "6. We use one more FC layer with softmax to derive class probabilities."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8gziiFuVd3nb"
      },
      "source": [
        "The visualization describes the forward pass of a model that processes inputs using convolutional neural networks (CNN) for text classification. Here's a step-by-step explanation:\n",
        "\n",
        "1. Tokenization: The input text is tokenized, which means breaking it into individual tokens or words. The shape of the input tensor is (batch_size, max_seq_len), where batch_size represents the number of samples in a batch, and max_seq_len represents the maximum length of the input sequences.\n",
        "\n",
        "2. Embedding: The tokenized inputs are then embedded using an embedding layer. This layer maps each token to a dense vector representation of a fixed dimension called the embedding_dim. The resulting tensor has a shape of (batch_size, max_seq_len, embedding_dim).\n",
        "\n",
        "3. Convolution and Batch Normalization: The embedded inputs are passed through a set of convolutional filters. Each filter has a filter_size (e.g., 2, 3, or 4) and is designed to capture n-gram features at the character level. The filters scan over the input sequences and produce feature maps. After convolution, batch normalization is applied to normalize the output of the convolutional layer.\n",
        "\n",
        "4. 1D Global Max Pooling: The feature maps obtained from the convolutional layer are subjected to 1D global max pooling. This operation selects the maximum value from each feature map, capturing the most relevant information for each filter. The result is a tensor with a shape of (batch_size, num_filters), where num_filters represents the number of filters used.\n",
        "\n",
        "5. Fully-Connected Layer (FC): The pooled outputs are then fed into a fully-connected layer, which performs a linear transformation on the inputs. This layer has dropout applied to prevent overfitting. The FC layer can learn more complex patterns and relationships in the extracted features.\n",
        "\n",
        "6. Output Layer: Finally, another fully-connected layer with softmax activation is used to derive class probabilities. The number of units in this layer is equal to the number of classes in the classification task."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {
        "id": "EeRb2CfoXVnc"
      },
      "outputs": [],
      "source": [
        "embedding_dim = 100\n",
        "hidden_dim = 100\n",
        "dropout_p = 0.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {
        "id": "gI7WWaG_hICi"
      },
      "outputs": [],
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self, embedding_dim, vocab_size, num_filters,\n",
        "                 filter_sizes, hidden_dim, dropout_p, num_classes,\n",
        "                 pretrained_embeddings=None, freeze_embeddings=False,\n",
        "                 padding_idx=0):\n",
        "        super(CNN, self).__init__()\n",
        "\n",
        "        # Filter sizes\n",
        "        self.filter_sizes = filter_sizes\n",
        "\n",
        "        # Initialize embeddings\n",
        "        if pretrained_embeddings is None:\n",
        "            self.embeddings = nn.Embedding(\n",
        "                embedding_dim=embedding_dim, num_embeddings=vocab_size,\n",
        "                padding_idx=padding_idx)\n",
        "        else:\n",
        "            pretrained_embeddings = torch.from_numpy(pretrained_embeddings).float()\n",
        "            self.embeddings = nn.Embedding(\n",
        "                embedding_dim=embedding_dim, num_embeddings=vocab_size,\n",
        "                padding_idx=padding_idx, _weight=pretrained_embeddings)\n",
        "\n",
        "        # Freeze embeddings or not\n",
        "        if freeze_embeddings:\n",
        "            self.embeddings.weight.requires_grad = False\n",
        "\n",
        "        # Conv weights\n",
        "        self.conv = nn.ModuleList(\n",
        "            [nn.Conv1d(in_channels=embedding_dim,\n",
        "                       out_channels=num_filters,\n",
        "                       kernel_size=f) for f in filter_sizes])\n",
        "\n",
        "        # FC weights\n",
        "        self.dropout = nn.Dropout(dropout_p)\n",
        "        self.fc1 = nn.Linear(num_filters*len(filter_sizes), hidden_dim)\n",
        "        self.fc2 = nn.Linear(hidden_dim, num_classes)\n",
        "\n",
        "    def forward(self, inputs, channel_first=False):\n",
        "\n",
        "        # Embed\n",
        "        x_in, = inputs\n",
        "        x_in = self.embeddings(x_in)\n",
        "\n",
        "        # Rearrange input so num_channels is in dim 1 (N, C, L)\n",
        "        if not channel_first:\n",
        "            x_in = x_in.transpose(1, 2)\n",
        "\n",
        "        # Conv outputs\n",
        "        z = []\n",
        "        max_seq_len = x_in.shape[2]\n",
        "        for i, f in enumerate(self.filter_sizes):\n",
        "            # `SAME` padding\n",
        "            padding_left = int((self.conv[i].stride[0]*(max_seq_len-1) - max_seq_len + self.filter_sizes[i])/2)\n",
        "            padding_right = int(math.ceil((self.conv[i].stride[0]*(max_seq_len-1) - max_seq_len + self.filter_sizes[i])/2))\n",
        "\n",
        "            # Conv + pool\n",
        "            _z = self.conv[i](F.pad(x_in, (padding_left, padding_right)))\n",
        "            _z = F.max_pool1d(_z, _z.size(2)).squeeze(2)\n",
        "            z.append(_z)\n",
        "\n",
        "        # Concat conv outputs\n",
        "        z = torch.cat(z, 1)\n",
        "\n",
        "        # FC layers\n",
        "        z = self.fc1(z)\n",
        "        z = self.dropout(z)\n",
        "        z = self.fc2(z)\n",
        "        return z\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Using GloVe"
      ],
      "metadata": {
        "id": "uKFI-nfxVc4L"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {
        "id": "rRTak3UHlF9-"
      },
      "outputs": [],
      "source": [
        "def load_glove_embeddings(embeddings_file):\n",
        "    \"\"\"Load embeddings from a file.\"\"\"\n",
        "    embeddings = {}\n",
        "    with open(embeddings_file, \"r\") as fp:\n",
        "        for index, line in enumerate(fp):\n",
        "            values = line.split()\n",
        "            word = values[0]\n",
        "            embedding = np.asarray(values[1:], dtype='float32')\n",
        "            embeddings[word] = embedding\n",
        "    return embeddings"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def make_embeddings_matrix(embeddings, word_index, embedding_dim):\n",
        "    \"\"\"Create embeddings matrix to use in Embedding layer.\"\"\"\n",
        "    embedding_matrix = np.zeros((len(word_index), embedding_dim))\n",
        "    for word, i in word_index.items():\n",
        "        embedding_vector = embeddings.get(word)\n",
        "        if embedding_vector is not None:\n",
        "            embedding_matrix[i] = embedding_vector\n",
        "    return embedding_matrix"
      ],
      "metadata": {
        "id": "kuC1-bKPXebu"
      },
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create embeddings\n",
        "embeddings_file = 'glove.6B.{0}d.txt'.format(embedding_dim)\n",
        "glove_embeddings = load_glove_embeddings(embeddings_file=embeddings_file)\n",
        "embedding_matrix = make_embeddings_matrix(\n",
        "    embeddings=glove_embeddings, word_index=tokenizer.token_to_index,\n",
        "    embedding_dim=embedding_dim)\n",
        "print (f\"<Embeddings(words={embedding_matrix.shape[0]}, dim={embedding_matrix.shape[1]})>\")"
      ],
      "metadata": {
        "id": "Pb9P7ubzLjPy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92c70e91-0102-4dab-eb85-00c853fd7397"
      },
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<Embeddings(words=500, dim=100)>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Experiments"
      ],
      "metadata": {
        "id": "ZW-qqC0cYv6r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim import Adam\n",
        "from sklearn.metrics import precision_recall_fscore_support"
      ],
      "metadata": {
        "id": "5pH8eW41LliH"
      },
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_filters = 50\n",
        "learning_rate = 1e-3\n",
        "patience = 5\n",
        "epochs = 10"
      ],
      "metadata": {
        "id": "-I9RgE5VY0za"
      },
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Trainer(object):\n",
        "    def __init__(self, model, device, loss_fn=None, optimizer=None, scheduler=None):\n",
        "\n",
        "        # Set params\n",
        "        self.model = model\n",
        "        self.device = device\n",
        "        self.loss_fn = loss_fn\n",
        "        self.optimizer = optimizer\n",
        "        self.scheduler = scheduler\n",
        "\n",
        "    def train_step(self, dataloader):\n",
        "        \"\"\"Train step.\"\"\"\n",
        "        # Set model to train mode\n",
        "        self.model.train()\n",
        "        loss = 0.0\n",
        "\n",
        "        # Iterate over train batches\n",
        "        for i, batch in enumerate(dataloader):\n",
        "\n",
        "            # Step\n",
        "            batch = [item.to(self.device) for item in batch]  # Set device\n",
        "            inputs, targets = batch[:-1], batch[-1]\n",
        "            self.optimizer.zero_grad()  # Reset gradients\n",
        "            z = self.model(inputs)  # Forward pass\n",
        "            J = self.loss_fn(z, targets)  # Define loss\n",
        "            J.backward()  # Backward pass\n",
        "            self.optimizer.step()  # Update weights\n",
        "\n",
        "            # Cumulative Metrics\n",
        "            loss += (J.detach().item() - loss) / (i + 1)\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def eval_step(self, dataloader):\n",
        "        \"\"\"Validation or test step.\"\"\"\n",
        "        # Set model to eval mode\n",
        "        self.model.eval()\n",
        "        loss = 0.0\n",
        "        y_trues, y_probs = [], []\n",
        "\n",
        "        # Iterate over val batches\n",
        "        with torch.inference_mode():\n",
        "            for i, batch in enumerate(dataloader):\n",
        "\n",
        "                # Step\n",
        "                batch = [item.to(self.device) for item in batch]  # Set device\n",
        "                inputs, y_true = batch[:-1], batch[-1]\n",
        "                z = self.model(inputs)  # Forward pass\n",
        "                J = self.loss_fn(z, y_true).item()\n",
        "\n",
        "                # Cumulative Metrics\n",
        "                loss += (J - loss) / (i + 1)\n",
        "\n",
        "                # Store outputs\n",
        "                y_prob = F.softmax(z).cpu().numpy()\n",
        "                y_probs.extend(y_prob)\n",
        "                y_trues.extend(y_true.cpu().numpy())\n",
        "\n",
        "        return loss, np.vstack(y_trues), np.vstack(y_probs)\n",
        "\n",
        "    def predict_step(self, dataloader):\n",
        "        \"\"\"Prediction step.\"\"\"\n",
        "        # Set model to eval mode\n",
        "        self.model.eval()\n",
        "        y_probs = []\n",
        "\n",
        "        # Iterate over val batches\n",
        "        with torch.inference_mode():\n",
        "            for i, batch in enumerate(dataloader):\n",
        "\n",
        "                # Forward pass w/ inputs\n",
        "                inputs, targets = batch[:-1], batch[-1]\n",
        "                z = self.model(inputs)\n",
        "\n",
        "                # Store outputs\n",
        "                y_prob = F.softmax(z).cpu().numpy()\n",
        "                y_probs.extend(y_prob)\n",
        "\n",
        "        return np.vstack(y_probs)\n",
        "\n",
        "    def train(self, epochs, patience, train_dataloader, val_dataloader):\n",
        "        best_val_loss = np.inf\n",
        "        for epoch in range(epochs):\n",
        "            # Steps\n",
        "            train_loss = self.train_step(dataloader=train_dataloader)\n",
        "            val_loss, _, _ = self.eval_step(dataloader=val_dataloader)\n",
        "            self.scheduler.step(val_loss)\n",
        "\n",
        "            # Early stopping\n",
        "            if val_loss < best_val_loss:\n",
        "                best_val_loss = val_loss\n",
        "                best_model = self.model\n",
        "                _patience = patience  # reset _patience\n",
        "            else:\n",
        "                _patience -= 1\n",
        "            if not _patience:  # 0\n",
        "                print(\"Stopping early!\")\n",
        "                break\n",
        "\n",
        "            # Logging\n",
        "            print(\n",
        "                f\"Epoch: {epoch+1} | \"\n",
        "                f\"train_loss: {train_loss:.5f}, \"\n",
        "                f\"val_loss: {val_loss:.5f}, \"\n",
        "                f\"lr: {self.optimizer.param_groups[0]['lr']:.2E}, \"\n",
        "                f\"_patience: {_patience}\"\n",
        "            )\n",
        "        return best_model"
      ],
      "metadata": {
        "id": "4XX9dlUya5Ia"
      },
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_metrics(y_true, y_pred, classes):\n",
        "    \"\"\"Per-class performance metrics.\"\"\"\n",
        "    # Performance\n",
        "    performance = {\"overall\": {}, \"class\": {}}\n",
        "\n",
        "    # Overall performance\n",
        "    metrics = precision_recall_fscore_support(y_true, y_pred, average=\"weighted\")\n",
        "    performance[\"overall\"][\"precision\"] = metrics[0]\n",
        "    performance[\"overall\"][\"recall\"] = metrics[1]\n",
        "    performance[\"overall\"][\"f1\"] = metrics[2]\n",
        "    performance[\"overall\"][\"num_samples\"] = np.float64(len(y_true))\n",
        "\n",
        "    # Per-class performance\n",
        "    metrics = precision_recall_fscore_support(y_true, y_pred, average=None)\n",
        "    for i in range(len(classes)):\n",
        "        performance[\"class\"][classes[i]] = {\n",
        "            \"precision\": metrics[0][i],\n",
        "            \"recall\": metrics[1][i],\n",
        "            \"f1\": metrics[2][i],\n",
        "            \"num_samples\": np.float64(metrics[3][i]),\n",
        "        }\n",
        "\n",
        "    return performance"
      ],
      "metadata": {
        "id": "VEHg8tw0cgfI"
      },
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Random Initialization"
      ],
      "metadata": {
        "id": "Mdhv8k3TdM6V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pretrained_embeddings = None\n",
        "freeze_embeddings = False"
      ],
      "metadata": {
        "id": "fjY1W-6ucgJp"
      },
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize model\n",
        "model = CNN(\n",
        "    embedding_dim=embedding_dim, vocab_size=VOCAB_SIZE,\n",
        "    num_filters=num_filters, filter_sizes=filter_sizes,\n",
        "    hidden_dim=hidden_dim, dropout_p=dropout_p, num_classes=num_classes,\n",
        "    pretrained_embeddings=pretrained_embeddings, freeze_embeddings=freeze_embeddings)\n",
        "model = model.to(device) # set device\n",
        "print (model.named_parameters)"
      ],
      "metadata": {
        "id": "VXYRiVoxd38t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70548ad2-4123-41b2-a834-e42579a12135"
      },
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<bound method Module.named_parameters of CNN(\n",
            "  (embeddings): Embedding(500, 100, padding_idx=0)\n",
            "  (conv): ModuleList(\n",
            "    (0): Conv1d(100, 50, kernel_size=(1,), stride=(1,))\n",
            "    (1): Conv1d(100, 50, kernel_size=(2,), stride=(1,))\n",
            "    (2): Conv1d(100, 50, kernel_size=(3,), stride=(1,))\n",
            "  )\n",
            "  (dropout): Dropout(p=0.1, inplace=False)\n",
            "  (fc1): Linear(in_features=150, out_features=100, bias=True)\n",
            "  (fc2): Linear(in_features=100, out_features=4, bias=True)\n",
            ")>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Loss\n",
        "class_weights_tensor = torch.Tensor(list(class_weights.values())).to(device)\n",
        "loss_fn = nn.CrossEntropyLoss(weight=class_weights_tensor)"
      ],
      "metadata": {
        "id": "6DAhI8sy0qOl"
      },
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define optimizer & scheduler\n",
        "optimizer = Adam(model.parameters(), lr=learning_rate)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    optimizer, mode=\"min\", factor=0.1, patience=3)"
      ],
      "metadata": {
        "id": "1scYNO7I1il3"
      },
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Trainer module\n",
        "trainer = Trainer(\n",
        "    model=model, device=device, loss_fn=loss_fn,\n",
        "    optimizer=optimizer, scheduler=scheduler)"
      ],
      "metadata": {
        "id": "0Z1Cpk5S1odP"
      },
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train\n",
        "best_model = trainer.train(\n",
        "    epochs, patience, train_dataloader, val_dataloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Su_usOU42sd9",
        "outputId": "758acfea-7881-4441-f312-1dcbcab8b01c"
      },
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-127-b117a8ba9edc>:21: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  batch = np.array(batch)\n",
            "<ipython-input-137-7e845f77bb2a>:55: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  y_prob = F.softmax(z).cpu().numpy()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 | train_loss: 0.87800, val_loss: 0.81630, lr: 1.00E-03, _patience: 5\n",
            "Epoch: 2 | train_loss: 0.78161, val_loss: 0.80710, lr: 1.00E-03, _patience: 5\n",
            "Epoch: 3 | train_loss: 0.75820, val_loss: 0.80246, lr: 1.00E-03, _patience: 5\n",
            "Epoch: 4 | train_loss: 0.74102, val_loss: 0.80422, lr: 1.00E-03, _patience: 4\n",
            "Epoch: 5 | train_loss: 0.72566, val_loss: 0.80684, lr: 1.00E-03, _patience: 3\n",
            "Epoch: 6 | train_loss: 0.71222, val_loss: 0.81617, lr: 1.00E-03, _patience: 2\n",
            "Epoch: 7 | train_loss: 0.69858, val_loss: 0.82561, lr: 1.00E-04, _patience: 1\n",
            "Stopping early!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get predictions\n",
        "test_loss, y_true, y_prob = trainer.eval_step(dataloader=test_dataloader)\n",
        "y_pred = np.argmax(y_prob, axis=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jypurHyy2vqN",
        "outputId": "560f2bb5-3f5c-4db5-93a6-8247e73e0139"
      },
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-127-b117a8ba9edc>:21: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  batch = np.array(batch)\n",
            "<ipython-input-137-7e845f77bb2a>:55: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  y_prob = F.softmax(z).cpu().numpy()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Determine performance\n",
        "performance = get_metrics(\n",
        "    y_true=y_test_enc, y_pred=y_pred, classes=label_encoder.classes)\n",
        "print (json.dumps(performance[\"overall\"], indent=2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8wd9Rk4x-wOI",
        "outputId": "7031e850-8547-4a20-f7c9-ef3a40393d6f"
      },
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"precision\": 0.6979587682039768,\n",
            "  \"recall\": 0.6836111111111111,\n",
            "  \"f1\": 0.6830445851490706,\n",
            "  \"num_samples\": 18000.0\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Glove (frozen)"
      ],
      "metadata": {
        "id": "klN2zGvmJxZH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pretrained_embeddings = embedding_matrix\n",
        "freeze_embeddings = True"
      ],
      "metadata": {
        "id": "xNyh_NQW-2Fw"
      },
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize model\n",
        "model = CNN(\n",
        "    embedding_dim=embedding_dim, vocab_size=VOCAB_SIZE,\n",
        "    num_filters=num_filters, filter_sizes=filter_sizes,\n",
        "    hidden_dim=hidden_dim, dropout_p=dropout_p, num_classes=num_classes,\n",
        "    pretrained_embeddings=pretrained_embeddings, freeze_embeddings=freeze_embeddings)\n",
        "model = model.to(device) # set device\n",
        "print (model.named_parameters)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nyZejGXuJ5AM",
        "outputId": "f40eab7d-3aff-4619-ae12-52a17b98108d"
      },
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<bound method Module.named_parameters of CNN(\n",
            "  (embeddings): Embedding(500, 100, padding_idx=0)\n",
            "  (conv): ModuleList(\n",
            "    (0): Conv1d(100, 50, kernel_size=(1,), stride=(1,))\n",
            "    (1): Conv1d(100, 50, kernel_size=(2,), stride=(1,))\n",
            "    (2): Conv1d(100, 50, kernel_size=(3,), stride=(1,))\n",
            "  )\n",
            "  (dropout): Dropout(p=0.1, inplace=False)\n",
            "  (fc1): Linear(in_features=150, out_features=100, bias=True)\n",
            "  (fc2): Linear(in_features=100, out_features=4, bias=True)\n",
            ")>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Loss\n",
        "class_weights_tensor = torch.Tensor(list(class_weights.values())).to(device)\n",
        "loss_fn = nn.CrossEntropyLoss(weight=class_weights_tensor)"
      ],
      "metadata": {
        "id": "Dt0R1JLZKK7E"
      },
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define optimizer & scheduler\n",
        "optimizer = Adam(model.parameters(), lr=learning_rate)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    optimizer, mode=\"min\", factor=0.1, patience=3)"
      ],
      "metadata": {
        "id": "Z3qnPYC7V_6T"
      },
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train\n",
        "best_model = trainer.train(\n",
        "    epochs, patience, train_dataloader, val_dataloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9rQkAvFiWCk7",
        "outputId": "cb9f7c97-59a2-4e7a-fd2c-3dab94f7744e"
      },
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-127-b117a8ba9edc>:21: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  batch = np.array(batch)\n",
            "<ipython-input-137-7e845f77bb2a>:55: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  y_prob = F.softmax(z).cpu().numpy()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 | train_loss: 0.64238, val_loss: 0.81059, lr: 1.00E-04, _patience: 5\n",
            "Epoch: 2 | train_loss: 0.63467, val_loss: 0.81676, lr: 1.00E-04, _patience: 4\n",
            "Epoch: 3 | train_loss: 0.62878, val_loss: 0.82257, lr: 1.00E-05, _patience: 3\n",
            "Epoch: 4 | train_loss: 0.61913, val_loss: 0.82145, lr: 1.00E-05, _patience: 2\n",
            "Epoch: 5 | train_loss: 0.61756, val_loss: 0.82160, lr: 1.00E-05, _patience: 1\n",
            "Stopping early!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get predictions\n",
        "test_loss, y_true, y_prob = trainer.eval_step(dataloader=test_dataloader)\n",
        "y_pred = np.argmax(y_prob, axis=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gXLo1ItcWJWp",
        "outputId": "7d8fc0cb-9793-4855-919e-8415ee03685c"
      },
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-127-b117a8ba9edc>:21: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  batch = np.array(batch)\n",
            "<ipython-input-137-7e845f77bb2a>:55: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  y_prob = F.softmax(z).cpu().numpy()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Determine performance\n",
        "performance = get_metrics(\n",
        "    y_true=y_test_enc, y_pred=y_pred, classes=label_encoder.classes)\n",
        "print (json.dumps(performance[\"overall\"], indent=2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T9MV1g-7WuJU",
        "outputId": "85bdcb9d-50cf-48be-ce4c-6fdeff0a3d24"
      },
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"precision\": 0.6963865285858517,\n",
            "  \"recall\": 0.6818888888888889,\n",
            "  \"f1\": 0.6813498868405675,\n",
            "  \"num_samples\": 18000.0\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Glove (fine-tuned)"
      ],
      "metadata": {
        "id": "_SGGqibdXlHn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pretrained_embeddings = embedding_matrix\n",
        "freeze_embeddings = False"
      ],
      "metadata": {
        "id": "NphfX9A6Xc1P"
      },
      "execution_count": 154,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize model\n",
        "model = CNN(\n",
        "    embedding_dim=embedding_dim, vocab_size=VOCAB_SIZE,\n",
        "    num_filters=num_filters, filter_sizes=filter_sizes,\n",
        "    hidden_dim=hidden_dim, dropout_p=dropout_p, num_classes=num_classes,\n",
        "    pretrained_embeddings=pretrained_embeddings, freeze_embeddings=freeze_embeddings)\n",
        "model = model.to(device) # set device\n",
        "print (model.named_parameters)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8-_49WwhXu3O",
        "outputId": "e31b6a9c-00c5-4025-de3f-3bc13f16690b"
      },
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<bound method Module.named_parameters of CNN(\n",
            "  (embeddings): Embedding(500, 100, padding_idx=0)\n",
            "  (conv): ModuleList(\n",
            "    (0): Conv1d(100, 50, kernel_size=(1,), stride=(1,))\n",
            "    (1): Conv1d(100, 50, kernel_size=(2,), stride=(1,))\n",
            "    (2): Conv1d(100, 50, kernel_size=(3,), stride=(1,))\n",
            "  )\n",
            "  (dropout): Dropout(p=0.1, inplace=False)\n",
            "  (fc1): Linear(in_features=150, out_features=100, bias=True)\n",
            "  (fc2): Linear(in_features=100, out_features=4, bias=True)\n",
            ")>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Loss\n",
        "class_weights_tensor = torch.Tensor(list(class_weights.values())).to(device)\n",
        "loss_fn = nn.CrossEntropyLoss(weight=class_weights_tensor)"
      ],
      "metadata": {
        "id": "OJOSBudsYVP7"
      },
      "execution_count": 156,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define optimizer & scheduler\n",
        "optimizer = Adam(model.parameters(), lr=learning_rate)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    optimizer, mode=\"min\", factor=0.1, patience=3)"
      ],
      "metadata": {
        "id": "Fsr5ehgsYv8I"
      },
      "execution_count": 157,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Trainer module\n",
        "trainer = Trainer(\n",
        "    model=model, device=device, loss_fn=loss_fn,\n",
        "    optimizer=optimizer, scheduler=scheduler)"
      ],
      "metadata": {
        "id": "yas6Ppb1Yz3Z"
      },
      "execution_count": 158,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train\n",
        "best_model = trainer.train(\n",
        "    epochs, patience, train_dataloader, val_dataloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "flHh4uEvY2e-",
        "outputId": "1eeecc6b-2402-4c59-ff88-131636bac074"
      },
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-127-b117a8ba9edc>:21: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  batch = np.array(batch)\n",
            "<ipython-input-137-7e845f77bb2a>:55: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  y_prob = F.softmax(z).cpu().numpy()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 | train_loss: 0.81494, val_loss: 0.78517, lr: 1.00E-03, _patience: 5\n",
            "Epoch: 2 | train_loss: 0.77088, val_loss: 0.77789, lr: 1.00E-03, _patience: 5\n",
            "Epoch: 3 | train_loss: 0.75664, val_loss: 0.77592, lr: 1.00E-03, _patience: 5\n",
            "Epoch: 4 | train_loss: 0.74489, val_loss: 0.77521, lr: 1.00E-03, _patience: 5\n",
            "Epoch: 5 | train_loss: 0.73391, val_loss: 0.77940, lr: 1.00E-03, _patience: 4\n",
            "Epoch: 6 | train_loss: 0.72346, val_loss: 0.78069, lr: 1.00E-03, _patience: 3\n",
            "Epoch: 7 | train_loss: 0.71270, val_loss: 0.78425, lr: 1.00E-03, _patience: 2\n",
            "Epoch: 8 | train_loss: 0.70264, val_loss: 0.78792, lr: 1.00E-04, _patience: 1\n",
            "Epoch: 9 | train_loss: 0.67157, val_loss: 0.77427, lr: 1.00E-04, _patience: 5\n",
            "Epoch: 10 | train_loss: 0.66087, val_loss: 0.77760, lr: 1.00E-04, _patience: 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get predictions\n",
        "test_loss, y_true, y_prob = trainer.eval_step(dataloader=test_dataloader)\n",
        "y_pred = np.argmax(y_prob, axis=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sjPBGeqtY7QE",
        "outputId": "2cc861d0-37da-4ed2-da1b-b12365e90934"
      },
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-127-b117a8ba9edc>:21: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  batch = np.array(batch)\n",
            "<ipython-input-137-7e845f77bb2a>:55: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  y_prob = F.softmax(z).cpu().numpy()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Determine performance\n",
        "performance = get_metrics(\n",
        "    y_true=y_test_enc, y_pred=y_pred, classes=label_encoder.classes)\n",
        "print (json.dumps(performance[\"overall\"], indent=2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d3YjOqWId-_X",
        "outputId": "75447135-8822-45f9-844e-c0140bf07e16"
      },
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"precision\": 0.706486056850685,\n",
            "  \"recall\": 0.6913333333333334,\n",
            "  \"f1\": 0.6911750405866612,\n",
            "  \"num_samples\": 18000.0\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save artifacts\n",
        "from pathlib import Path\n",
        "dir = Path(\"cnn\")\n",
        "dir.mkdir(parents=True, exist_ok=True)\n",
        "label_encoder.save(fp=Path(dir, \"label_encoder.json\"))\n",
        "tokenizer.save(fp=Path(dir, \"tokenizer.json\"))\n",
        "torch.save(best_model.state_dict(), Path(dir, \"model.pt\"))\n",
        "with open(Path(dir, \"performance.json\"), \"w\") as fp:\n",
        "    json.dump(performance, indent=2, sort_keys=False, fp=fp)"
      ],
      "metadata": {
        "id": "qNI4ihLFeCsX"
      },
      "execution_count": 162,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Inference"
      ],
      "metadata": {
        "id": "JDqUYZD2efW3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_probability_distribution(y_prob, classes):\n",
        "    \"\"\"Create a dict of class probabilities from an array.\"\"\"\n",
        "    results = {}\n",
        "    for i, class_ in enumerate(classes):\n",
        "        results[class_] = np.float64(y_prob[i])\n",
        "    sorted_results = {k: v for k, v in sorted(\n",
        "        results.items(), key=lambda item: item[1], reverse=True)}\n",
        "    return sorted_results"
      ],
      "metadata": {
        "id": "NE_-m58-eJGp"
      },
      "execution_count": 163,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load artifacts\n",
        "device = torch.device(\"cpu\")\n",
        "label_encoder = LabelEncoder.load(fp=Path(dir, \"label_encoder.json\"))\n",
        "tokenizer = Tokenizer.load(fp=Path(dir, \"tokenizer.json\"))\n",
        "model = CNN(\n",
        "    embedding_dim=embedding_dim, vocab_size=VOCAB_SIZE,\n",
        "    num_filters=num_filters, filter_sizes=filter_sizes,\n",
        "    hidden_dim=hidden_dim, dropout_p=dropout_p, num_classes=num_classes,\n",
        "    pretrained_embeddings=pretrained_embeddings, freeze_embeddings=freeze_embeddings)\n",
        "model.load_state_dict(torch.load(Path(dir, \"model.pt\"), map_location=device))\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tkZEVw7-ei0A",
        "outputId": "cbc47fac-efab-4053-b59d-9de38bf34c7f"
      },
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CNN(\n",
              "  (embeddings): Embedding(500, 100, padding_idx=0)\n",
              "  (conv): ModuleList(\n",
              "    (0): Conv1d(100, 50, kernel_size=(1,), stride=(1,))\n",
              "    (1): Conv1d(100, 50, kernel_size=(2,), stride=(1,))\n",
              "    (2): Conv1d(100, 50, kernel_size=(3,), stride=(1,))\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (fc1): Linear(in_features=150, out_features=100, bias=True)\n",
              "  (fc2): Linear(in_features=100, out_features=4, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 164
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize trainer\n",
        "trainer = Trainer(model=model, device=device)"
      ],
      "metadata": {
        "id": "UkCjYeXMexPu"
      },
      "execution_count": 165,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataloader\n",
        "text = \"The final tennis tournament starts next week.\"\n",
        "X = tokenizer.texts_to_sequences([preprocess(text)])\n",
        "print (tokenizer.sequences_to_texts(X))\n",
        "y_filler = label_encoder.encode([label_encoder.classes[0]]*len(X))\n",
        "dataset = Dataset(X=X, y=y_filler, max_filter_size=max_filter_size)\n",
        "dataloader = dataset.create_dataloader(batch_size=batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HlLGLzAoxoPl",
        "outputId": "4327f6f8-029e-46db-c305-4983c601771c"
      },
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['final <UNK> <UNK> <UNK> next week']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Inference\n",
        "y_prob = trainer.predict_step(dataloader)\n",
        "y_pred = np.argmax(y_prob, axis=1)\n",
        "label_encoder.decode(y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f6m5R2W1xseZ",
        "outputId": "a1499718-0022-4e79-db95-9f84a6a04614"
      },
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-127-b117a8ba9edc>:21: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  batch = np.array(batch)\n",
            "<ipython-input-137-7e845f77bb2a>:76: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  y_prob = F.softmax(z).cpu().numpy()\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Sports']"
            ]
          },
          "metadata": {},
          "execution_count": 167
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Class distributions\n",
        "prob_dist = get_probability_distribution(y_prob=y_prob[0], classes=label_encoder.classes)\n",
        "print (json.dumps(prob_dist, indent=2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fXfpzEbzxyXL",
        "outputId": "7f7a252a-2142-4a44-d2a5-fd7232b53005"
      },
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"Sports\": 0.710612952709198,\n",
            "  \"World\": 0.14299936592578888,\n",
            "  \"Sci/Tech\": 0.11295132339000702,\n",
            "  \"Business\": 0.03343639895319939\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Interpretability\n"
      ],
      "metadata": {
        "id": "ykIX2ZLjx6Hn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class InterpretableCNN(nn.Module):\n",
        "    def __init__(self, embedding_dim, vocab_size, num_filters,\n",
        "                 filter_sizes, hidden_dim, dropout_p, num_classes,\n",
        "                 pretrained_embeddings=None, freeze_embeddings=False,\n",
        "                 padding_idx=0):\n",
        "        super(InterpretableCNN, self).__init__()\n",
        "\n",
        "        # Filter sizes\n",
        "        self.filter_sizes = filter_sizes\n",
        "\n",
        "        # Initialize embeddings\n",
        "        if pretrained_embeddings is None:\n",
        "            self.embeddings = nn.Embedding(\n",
        "                embedding_dim=embedding_dim, num_embeddings=vocab_size,\n",
        "                padding_idx=padding_idx)\n",
        "        else:\n",
        "            pretrained_embeddings = torch.from_numpy(pretrained_embeddings).float()\n",
        "            self.embeddings = nn.Embedding(\n",
        "                embedding_dim=embedding_dim, num_embeddings=vocab_size,\n",
        "                padding_idx=padding_idx, _weight=pretrained_embeddings)\n",
        "\n",
        "        # Freeze embeddings or not\n",
        "        if freeze_embeddings:\n",
        "            self.embeddings.weight.requires_grad = False\n",
        "\n",
        "        # Conv weights\n",
        "        self.conv = nn.ModuleList(\n",
        "            [nn.Conv1d(in_channels=embedding_dim,\n",
        "                       out_channels=num_filters,\n",
        "                       kernel_size=f) for f in filter_sizes])\n",
        "\n",
        "        # FC weights\n",
        "        self.dropout = nn.Dropout(dropout_p)\n",
        "        self.fc1 = nn.Linear(num_filters*len(filter_sizes), hidden_dim)\n",
        "        self.fc2 = nn.Linear(hidden_dim, num_classes)\n",
        "\n",
        "    def forward(self, inputs, channel_first=False):\n",
        "\n",
        "        # Embed\n",
        "        x_in, = inputs\n",
        "        x_in = self.embeddings(x_in)\n",
        "\n",
        "        # Rearrange input so num_channels is in dim 1 (N, C, L)\n",
        "        if not channel_first:\n",
        "            x_in = x_in.transpose(1, 2)\n",
        "\n",
        "        # Conv outputs\n",
        "        z = []\n",
        "        max_seq_len = x_in.shape[2]\n",
        "        for i, f in enumerate(self.filter_sizes):\n",
        "            # `SAME` padding\n",
        "            padding_left = int((self.conv[i].stride[0]*(max_seq_len-1) - max_seq_len + self.filter_sizes[i])/2)\n",
        "            padding_right = int(math.ceil((self.conv[i].stride[0]*(max_seq_len-1) - max_seq_len + self.filter_sizes[i])/2))\n",
        "\n",
        "            # Conv + pool\n",
        "            _z = self.conv[i](F.pad(x_in, (padding_left, padding_right)))\n",
        "            z.append(_z.cpu().numpy())\n",
        "\n",
        "        return z\n"
      ],
      "metadata": {
        "id": "F1nFAvJ-x1_m"
      },
      "execution_count": 169,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pretrained_embeddings = embedding_matrix\n",
        "freeze_embeddings = False"
      ],
      "metadata": {
        "id": "q371wDSex_H3"
      },
      "execution_count": 170,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize model\n",
        "interpretable_model = InterpretableCNN(\n",
        "    embedding_dim=embedding_dim, vocab_size=VOCAB_SIZE,\n",
        "    num_filters=num_filters, filter_sizes=filter_sizes,\n",
        "    hidden_dim=hidden_dim, dropout_p=dropout_p, num_classes=num_classes,\n",
        "    pretrained_embeddings=pretrained_embeddings, freeze_embeddings=freeze_embeddings)\n",
        "interpretable_model.load_state_dict(torch.load(Path(dir, \"model.pt\"), map_location=device))\n",
        "interpretable_model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KOzLentzycF3",
        "outputId": "784ea3ab-a5e8-427c-c1a2-e13d36a83247"
      },
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "InterpretableCNN(\n",
              "  (embeddings): Embedding(500, 100, padding_idx=0)\n",
              "  (conv): ModuleList(\n",
              "    (0): Conv1d(100, 50, kernel_size=(1,), stride=(1,))\n",
              "    (1): Conv1d(100, 50, kernel_size=(2,), stride=(1,))\n",
              "    (2): Conv1d(100, 50, kernel_size=(3,), stride=(1,))\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (fc1): Linear(in_features=150, out_features=100, bias=True)\n",
              "  (fc2): Linear(in_features=100, out_features=4, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 171
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get conv outputs\n",
        "interpretable_model.eval()\n",
        "conv_outputs = []\n",
        "with torch.inference_mode():\n",
        "    for i, batch in enumerate(dataloader):\n",
        "\n",
        "        # Forward pass w/ inputs\n",
        "        inputs, targets = batch[:-1], batch[-1]\n",
        "        z = interpretable_model(inputs)\n",
        "\n",
        "        # Store conv outputs\n",
        "        conv_outputs.extend(z)\n",
        "\n",
        "conv_outputs = np.vstack(conv_outputs)\n",
        "print (conv_outputs.shape) # (len(filter_sizes), num_filters, max_seq_len)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LlfAHx1kynGv",
        "outputId": "40d9030f-df4a-43a5-fefa-a7582418dd61"
      },
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3, 50, 6)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-127-b117a8ba9edc>:21: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  batch = np.array(batch)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_index = 0\n",
        "print (f\"Original text:\\n{text}\")\n",
        "print (f\"\\nPreprocessed text:\\n{tokenizer.sequences_to_texts(X)[0]}\")\n",
        "print (\"\\nMost important n-grams:\")\n",
        "# Process conv outputs for each unique filter size\n",
        "for i, filter_size in enumerate(filter_sizes):\n",
        "\n",
        "    # Identify most important n-gram (excluding last token)\n",
        "    popular_indices = collections.Counter([np.argmax(conv_output) \\\n",
        "            for conv_output in conv_outputs[i]])\n",
        "\n",
        "    # Get corresponding text\n",
        "    start = popular_indices.most_common(1)[-1][0]\n",
        "    n_gram = \" \".join([token for token in tokens[start:start+filter_size]])\n",
        "    print (f\"[{filter_size}-gram]: {n_gram}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tlcOw8bQyqju",
        "outputId": "33e4adcb-ac27-435b-af8d-ca23511cc89d"
      },
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original text:\n",
            "The final tennis tournament starts next week.\n",
            "\n",
            "Preprocessed text:\n",
            "final <UNK> <UNK> <UNK> next week\n",
            "\n",
            "Most important n-grams:\n",
            "[1-gram]: <UNK>\n",
            "[2-gram]: final <UNK>\n",
            "[3-gram]: final <UNK> <UNK>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "USEATCr3yuQg"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMkrDUX/wdLowQsAN3As0XX",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}