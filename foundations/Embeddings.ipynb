{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyON/B5zftYnmOPZe+m7RLXy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ibraheem101/mlops/blob/main/foundations/Embeddings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Word embeddings"
      ],
      "metadata": {
        "id": "vYuaJ95yvnXS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The motivation for word embeddings in natural language processing (NLP) arises from the need to represent words in a numerical format that captures their semantic and syntactic similarities. Traditional approaches in NLP, such as one-hot encoding or bag-of-words representations, treat words as discrete symbols with no inherent meaning or relationship between them. However, words do possess rich contextual information and often exhibit semantic connections based on their usage in text.\n",
        "\n",
        "Word embeddings aim to address this limitation by representing words as dense vectors in a continuous vector space. The key motivation behind word embeddings is to capture the meaning and relationships between words based on their distributional properties in a given corpus. The underlying idea is that words that occur in similar contexts tend to have similar meanings.\n",
        "\n",
        "By learning word embeddings, NLP models can benefit from several advantages:\n",
        "\n",
        "* Semantic Similarity: Word embeddings capture semantic relationships between words. Words with similar meanings or concepts are represented by vectors that are closer to each other in the embedding space. For example, the vectors for \"king\" and \"queen\" would be closer to each other than to the vector for \"apple.\"\n",
        "\n",
        "* Syntactic Regularities: Word embeddings can capture syntactic regularities and analogies between words. For example, the vector difference between \"man\" and \"woman\" might be similar to the vector difference between \"king\" and \"queen,\" capturing the analogy between gendered terms.\n",
        "\n",
        "* Dimensionality Reduction: Word embeddings provide a lower-dimensional representation of words compared to one-hot encoding or bag-of-words models. This reduces the dimensionality of the input space and helps mitigate the curse of dimensionality in NLP tasks.\n",
        "\n",
        "* Generalization: Word embeddings can generalize to unseen words or rare words by leveraging the similarities learned from the training data. Models can infer similarities and relationships for words not explicitly encountered during training, which is valuable for handling out-of-vocabulary words.\n",
        "\n",
        "* Efficiency: Word embeddings reduce the computational complexity of NLP models by representing words as continuous vectors. This enables efficient processing and computation compared to sparse representations."
      ],
      "metadata": {
        "id": "NOkYk3NsvqBt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "46XqVPhSmysu"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import json\n",
        "import math\n",
        "import nltk\n",
        "import torch\n",
        "import gensim\n",
        "import random\n",
        "import urllib\n",
        "import itertools\n",
        "import collections\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can learn embeddings by creating our models in PyTorch but first, we're going to use a library that specializes in embeddings and topic modeling called Gensim."
      ],
      "metadata": {
        "id": "OZuNpyFHv-p7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download(\"punkt\")\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vFM9Wu9om-54",
        "outputId": "cd131317-06b8-473a-fb06-95e326eed490"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seed = 1234"
      ],
      "metadata": {
        "id": "lZCeq1o8xVFK"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def set_seeds(seed=1234):\n",
        "    \"\"\"Set seeds for reproducibility.\"\"\"\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed) # multi-GPU"
      ],
      "metadata": {
        "id": "f5SqRRYjwFMx"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "set_seeds(seed = seed)"
      ],
      "metadata": {
        "id": "drh1o9JTxSCb"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load data"
      ],
      "metadata": {
        "id": "RqDiCvl90hwN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split text into sentences\n",
        "tokenizer = nltk.data.load(\"tokenizers/punkt/english.pickle\")\n",
        "book = urllib.request.urlopen(url=\"https://raw.githubusercontent.com/GokuMohandas/Made-With-ML/main/datasets/harrypotter.txt\")\n",
        "sentences = tokenizer.tokenize(str(book.read()))\n",
        "print (f\"{len(sentences)} sentences\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3xrDMHYvxWsJ",
        "outputId": "925ed696-6d89-432a-f112-ed105ab23872"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12449 sentences\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentences[26]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "HBVv7FIU0n_P",
        "outputId": "178f5ba9-a05e-4063-cba6-d6b334bd935e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'He seemed unable to prevent himself from glancing upward every minute or so.\\\\r\\\\n\"Yaxley.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(text):\n",
        "\n",
        "    # lowercasing\n",
        "    text = text.lower()\n",
        "\n",
        "    # Spacing and filters\n",
        "    text = re.sub(r\"([-;;.,!?<=>])\", r\" \\1 \", text)\n",
        "    text = re.sub(\"[^A-Za-z0-9]+\", \" \", text) # remove non alphanumeric chars\n",
        "    text = re.sub(\" +\", \" \", text)  # remove multiple spaces\n",
        "    text = text.strip()\n",
        "\n",
        "    # Separate into word tokens\n",
        "    text = text.split(\" \")\n",
        "\n",
        "    return text"
      ],
      "metadata": {
        "id": "VQJJWEOZ0rQO"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(sentences[27])\n",
        "sentences = [preprocess(sentence) for sentence in sentences]\n",
        "print(sentences[27])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8cHz3ynG4VYh",
        "outputId": "d8884972-e534-4c5b-9817-83bf6a55bc29"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Snape,\" said a high, clear voice from the head of the table.\n",
            "['snape', 'said', 'a', 'high', 'clear', 'voice', 'from', 'the', 'head', 'of', 'the', 'table']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<details>\n",
        "    <summary>Approaches to learning embeddings</summary>\n",
        "\n",
        "1. Continuous Bag of Words (CBOW):\n",
        "In CBOW, the objective is to predict the target word based on the context words surrounding it.\n",
        "The model takes a fixed-size context window of words as input and tries to predict the target word in the middle.\n",
        "The context words are typically represented as one-hot vectors or pre-trained word embeddings.\n",
        "The model is trained using a neural network, where the context words are passed through an embedding layer, followed by a hidden layer, and finally a softmax output layer.\n",
        "The embedding layer learns the dense representations (embeddings) of the context words, which are updated during training to improve the prediction accuracy.\n",
        "The learned embeddings capture the semantic and syntactic relationships between words based on their co-occurrence patterns.\n",
        "\n",
        "2. Skip-gram:\n",
        "In skip-gram, the objective is to predict the context words given a target word.\n",
        "The model takes a target word as input and tries to predict the surrounding context words.\n",
        "Similar to CBOW, the context words can be represented as one-hot vectors or pre-trained embeddings.\n",
        "The model architecture consists of an embedding layer followed by a hidden layer and a softmax output layer.\n",
        "During training, the model adjusts the embeddings to maximize the probability of predicting the correct context words.\n",
        "The skip-gram approach is useful when we want to focus on rare words and capture more fine-grained relationships between words.\n",
        "\n",
        "3. Language Modeling (LM):\n",
        "Language modeling involves predicting the next word in a sequence of words given the previous words.\n",
        "The objective of LM is to learn the probability distribution of words in a language.\n",
        "The model takes a sequence of words as input and tries to predict the next word.\n",
        "It typically uses recurrent neural network (RNN) architectures, such as LSTM or GRU, to capture the sequential dependencies between words.\n",
        "The embeddings are learned as part of the training process, where the model updates the embeddings based on the predicted probabilities.\n",
        "Language models can be trained on large text corpora and can capture the contextual relationships between words.\n",
        "These approaches learn word embeddings by training neural network models on large amounts of text data. By considering the context of words, they capture the semantic and syntactic relationships, allowing words with similar meanings or usage to have similar embeddings. The resulting embeddings can then be used in various NLP tasks such as sentiment analysis, machine translation, and text generation.\n",
        "</details>"
      ],
      "metadata": {
        "id": "bfeiD7r0INaq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Word2vec\n",
        "[Understand Word2vec](https://mccormickml.com/2016/04/19/word2vec-tutorial-the-skip-gram-model/)"
      ],
      "metadata": {
        "id": "wJvvr4P9SyHM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import KeyedVectors\n",
        "from gensim.models import Word2Vec"
      ],
      "metadata": {
        "id": "PPzUkEzKP-kA"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim = 100\n",
        "window = 5\n",
        "min_count = 3 # Ignores all words with total frequency lower than this\n",
        "skip_gram = 1 # 0 = CBOW\n",
        "negative_sampling = 20"
      ],
      "metadata": {
        "id": "wX3gYFXDQQEA"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Super fast because of optimized C code under the hood\n",
        "w2v = Word2Vec(\n",
        "    sentences=sentences, vector_size=embedding_dim,\n",
        "    window=window, min_count=min_count,\n",
        "    sg=skip_gram, negative=negative_sampling)\n",
        "print(w2v)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GUJYECpHVz25",
        "outputId": "efa358e3-07e5-4818-cef4-679781f7efd3"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word2Vec<vocab=4937, vector_size=100, alpha=0.025>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Vector for each word\n",
        "w2v.wv.get_vector(\"harry\"), len(w2v.wv.get_vector(\"harry\")) #embedding vector e"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HcdJuyYsWB-8",
        "outputId": "d1405a18-4abc-48c2-94ca-21a7ce135c1e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([-8.36122483e-02,  3.72593522e-01,  7.01045478e-03,  8.98950547e-02,\n",
              "         1.65470481e-01, -3.51022661e-01,  2.50414550e-01,  3.85206997e-01,\n",
              "        -7.50519097e-01, -2.80024737e-01,  3.34674902e-02, -3.67605567e-01,\n",
              "        -1.98151469e-01,  1.24584325e-02, -6.27987012e-02, -6.03984036e-02,\n",
              "         4.48846102e-01, -2.03901887e-01, -5.90737045e-01, -2.80682683e-01,\n",
              "        -1.23700075e-01,  1.85041964e-01,  1.83086127e-01, -2.38956332e-01,\n",
              "         1.99852169e-01, -9.25628617e-02, -4.75979924e-01,  3.17589611e-01,\n",
              "        -1.11513078e-01,  2.78555248e-02,  2.56654620e-01,  1.25676230e-01,\n",
              "        -2.87806004e-01,  2.70128429e-01,  3.36311273e-02,  2.01222792e-01,\n",
              "        -8.24235305e-02,  6.51640147e-02,  2.08387673e-01, -1.66490674e-01,\n",
              "        -1.41929612e-01, -4.12383407e-01,  2.02513486e-02,  1.38338236e-02,\n",
              "         1.29887223e-01, -1.80447340e-01, -2.18640149e-01, -2.97859479e-02,\n",
              "        -1.94274127e-01, -8.74161497e-02,  4.31444317e-01, -2.20782980e-01,\n",
              "         2.17492267e-01,  2.45103061e-01, -2.44479477e-01, -5.08046031e-01,\n",
              "         2.45046258e-01, -3.96575302e-01, -2.89001673e-01,  1.09239407e-01,\n",
              "         2.80767441e-01,  6.10191561e-02,  5.09853780e-01,  7.56558729e-05,\n",
              "        -9.23114270e-02,  2.48856440e-01,  4.06544954e-02,  6.84994459e-02,\n",
              "        -1.67132124e-01, -3.17372352e-01, -9.54479575e-02,  3.97401303e-01,\n",
              "         3.37821573e-01,  1.00568689e-01,  1.38540089e-01,  9.85773951e-02,\n",
              "        -2.72089038e-02,  1.68320626e-01, -2.09604278e-01, -3.56872529e-01,\n",
              "        -4.57921922e-01, -3.51323038e-02, -2.11950652e-02, -8.17782655e-02,\n",
              "         1.95614219e-01, -1.22142747e-01,  2.07623631e-01,  6.38172403e-02,\n",
              "         1.51264414e-01, -2.09628105e-01, -7.90669676e-03,  2.00846031e-01,\n",
              "        -1.07243605e-01,  3.64665873e-02,  2.71118730e-01, -1.75328225e-01,\n",
              "         1.57482296e-01,  9.30071324e-02,  2.72730708e-01,  3.26446295e-02],\n",
              "       dtype=float32),\n",
              " 100)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get nearest neighbors (excluding itself)\n",
        "w2v.wv.most_similar(positive=\"man\", topn=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IG0DbNm5XDOP",
        "outputId": "8b434b17-d33b-4e46-f2a5-449ecabcbb7a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('wizard', 0.9163126945495605),\n",
              " ('witch', 0.8928037881851196),\n",
              " ('woman', 0.8813951015472412),\n",
              " ('odd', 0.8680001497268677),\n",
              " ('familiar', 0.8580108880996704)]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving and loading\n",
        "w2v.wv.save_word2vec_format(\"model.bin\", binary=True)\n",
        "w2v = KeyedVectors.load_word2vec_format(\"model.bin\", binary=True)"
      ],
      "metadata": {
        "id": "7YB1mT9yXXDD"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### FastText\n",
        "When a word doesn't exist in our vocabulary, there are a few approaches we can take to handle it:\n",
        "\n",
        "UNK Token:\n",
        "\n",
        "One common approach is to assign a special token, often called the \"UNK\" token, to represent out-of-vocabulary words.\n",
        "During training, if a word is encountered that is not present in the vocabulary, it is replaced with the UNK token.\n",
        "The UNK token allows the model to learn a representation for unknown words and treat them similarly during inference.\n",
        "FastText:\n",
        "\n",
        "FastText, as you mentioned, uses character-level n-grams to embed words. This technique enables it to handle rare words, misspelled words, and even words that are not present in the training corpus.\n",
        "By breaking down words into smaller subword units (character n-grams), FastText can still capture some information about the meaning of the word, even if it is unseen.\n",
        "When encountering an out-of-vocabulary word, FastText can leverage the character n-gram information to generate an embedding for the word based on the embeddings of its subword units.\n",
        "This approach can be particularly useful in scenarios where the vocabulary is limited or when dealing with morphologically rich languages."
      ],
      "metadata": {
        "id": "ELu7q8i1Zzj6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import FastText"
      ],
      "metadata": {
        "id": "TH_63DHYZqLe"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Super fast because of optimized C code under the hood\n",
        "ft = FastText(sentences=sentences, vector_size=embedding_dim,\n",
        "              window=window, min_count=min_count,\n",
        "              sg=skip_gram, negative=negative_sampling)\n",
        "print(ft)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K6VEMPqebFZ0",
        "outputId": "6cb3a29c-f766-498a-9e81-899782504fe9"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FastText<vocab=4937, vector_size=100, alpha=0.025>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This word doesn't exist so the word2vec model will error out\n",
        "try:\n",
        "    w2v.most_similar(positive=\"scarring\", topn=5)\n",
        "except KeyError:\n",
        "    print(\"The word doesn't exist in the vocabulary\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WqzsTmlEb0hx",
        "outputId": "562fea29-ac88-4a2c-85aa-6a134eb17480"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The word doesn't exist in the vocabulary\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# FastText will use n-grams to embed an OOV word\n",
        "ft.wv.most_similar(positive=\"scarring\", topn=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AFuEx4qBbgrG",
        "outputId": "96f4cf67-259c-417b-aad6-26a212ec4c6c"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('quivering', 0.9931723475456238),\n",
              " ('shuddering', 0.9916975498199463),\n",
              " ('dabbing', 0.9912965297698975),\n",
              " ('squeezing', 0.9912393689155579),\n",
              " ('wriggling', 0.9908320307731628)]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save and loading\n",
        "ft.wv.save(\"model.bin\")\n",
        "ft = KeyedVectors.load(\"model.bin\")"
      ],
      "metadata": {
        "id": "Y7Alz9ctbxVn"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ft.most_similar(positive=\"scarring\", topn=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_Hk-_56coLN",
        "outputId": "0024a962-3bbe-46a1-c55d-3c63e7378b1c"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('quivering', 0.9931723475456238),\n",
              " ('shuddering', 0.9916975498199463),\n",
              " ('dabbing', 0.9912965297698975),\n",
              " ('squeezing', 0.9912393689155579),\n",
              " ('wriggling', 0.9908320307731628)]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### GloVe\n",
        "GloVe (Global Vectors for Word Representation) is an unsupervised learning algorithm for generating word embeddings. It constructs a co-occurrence matrix from a large corpus of text, initializes word vectors, defines an objective function based on co-occurrence statistics, and optimizes the word vectors to capture semantic relationships. The resulting word embeddings are dense vector representations that capture similarities between words. GloVe leverages global statistical information and performs well in various NLP tasks."
      ],
      "metadata": {
        "id": "YLhWTib8vfwl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from io import BytesIO\n",
        "from zipfile import ZipFile\n",
        "from urllib.request import urlopen\n",
        "from sklearn.decomposition import PCA\n",
        "from gensim.scripts.glove2word2vec import glove2word2vec"
      ],
      "metadata": {
        "id": "sPE2Gm6Qcqdi"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_embeddings(words, embeddings, pca_results):\n",
        "    for word in words:\n",
        "        index = embeddings.index_to_key.index(word)\n",
        "        plt.scatter(pca_results[index, 0], pca_results[index, 1])\n",
        "        plt.annotate(word, xy=(pca_results[index, 0], pca_results[index, 1]))\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "Z_NO3aTowNMI"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<details>\n",
        "    <summary>Explanation</summary>\n",
        "    \n",
        "The function plot_embeddings takes three arguments: words, embeddings, and pca_results. Here's a breakdown of what the function does:\n",
        "It iterates over each word in the words list.\n",
        "For each word, it retrieves the corresponding index in the embeddings object using embeddings.index2word.index(word).\n",
        "It plots a scatter point on a 2D plot using the x and y coordinates from pca_results.\n",
        "It annotates the scatter point with the word using plt.annotate.\n",
        "Finally, it displays the plot using plt.show().\n",
        "The purpose of this function is to visualize word embeddings in a 2D space using PCA (Principal Component Analysis) results. It plots the words as scatter points and annotates each point with its corresponding word. The embeddings object represents a collection of word embeddings, and pca_results contains the PCA-transformed coordinates for each embedding. The words list specifies which words to visualize.\n",
        "</details>"
      ],
      "metadata": {
        "id": "E2swLUKuxdK3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load"
      ],
      "metadata": {
        "id": "FghfmFsO0w8s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cd content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dvyM2Cmrm62j",
        "outputId": "8e410545-09e9-43c3-f577-725a24b614e2"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: 'content'\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cp kaggle.json ~/.kaggle/"
      ],
      "metadata": {
        "id": "lUCilc27zYSP"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! chmod 600 /root/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "dDx78yI1zxs6"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! kaggle datasets download anindya2906/glove6b/download?datasetVersionNumber=1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TLhIG3dAydCW",
        "outputId": "2080b2be-7904-450d-b71f-32f5d284baef"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "glove6b.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Unzip the file (may take ~3-5 minutes)\n",
        "# Specify the path to the zip file\n",
        "zip_path = \"../content/glove6b.zip\"\n",
        "\n",
        "# Open the zip file\n",
        "with ZipFile(zip_path, 'r') as zip_ref:\n",
        "    # Extract all the contents of the zip file\n",
        "    zip_ref.extractall(\"../content/\")"
      ],
      "metadata": {
        "id": "300lyFGU0zL-"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Write embeddings to file\n",
        "embeddings_file = \"glove.6B.{0}d.txt\".format(embedding_dim)"
      ],
      "metadata": {
        "id": "u8_-efhTyCF3"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preview of the GloVe embeddings file\n",
        "with open(embeddings_file, \"r\") as fp:\n",
        "    line = next(fp)\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    embedding = np.asarray(values[1:], dtype='float32')\n",
        "    print (f\"word: {word}\")\n",
        "    print (f\"embedding:\\n{embedding}\")\n",
        "    print (f\"embedding dim: {len(embedding)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kx1Wa8i72GEo",
        "outputId": "33c2176b-9399-4ca9-84b5-8eefa224ec81"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "word: the\n",
            "embedding:\n",
            "[-0.038194 -0.24487   0.72812  -0.39961   0.083172  0.043953 -0.39141\n",
            "  0.3344   -0.57545   0.087459  0.28787  -0.06731   0.30906  -0.26384\n",
            " -0.13231  -0.20757   0.33395  -0.33848  -0.31743  -0.48336   0.1464\n",
            " -0.37304   0.34577   0.052041  0.44946  -0.46971   0.02628  -0.54155\n",
            " -0.15518  -0.14107  -0.039722  0.28277   0.14393   0.23464  -0.31021\n",
            "  0.086173  0.20397   0.52624   0.17164  -0.082378 -0.71787  -0.41531\n",
            "  0.20335  -0.12763   0.41367   0.55187   0.57908  -0.33477  -0.36559\n",
            " -0.54857  -0.062892  0.26584   0.30205   0.99775  -0.80481  -3.0243\n",
            "  0.01254  -0.36942   2.2167    0.72201  -0.24978   0.92136   0.034514\n",
            "  0.46745   1.1079   -0.19358  -0.074575  0.23353  -0.052062 -0.22044\n",
            "  0.057162 -0.15806  -0.30798  -0.41625   0.37972   0.15006  -0.53212\n",
            " -0.2055   -1.2526    0.071624  0.70565   0.49744  -0.42063   0.26148\n",
            " -1.538    -0.30223  -0.073438 -0.28312   0.37104  -0.25217   0.016215\n",
            " -0.017099 -0.38984   0.87424  -0.72569  -0.51058  -0.52028  -0.1459\n",
            "  0.8278    0.27062 ]\n",
            "embedding dim: 100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save GloVe embeddings to local directory in word2vec format\n",
        "word2vec_output_file = \"{0}.word2vec\".format(embeddings_file)\n",
        "glove2word2vec(embeddings_file, word2vec_output_file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4vXava8c2YMS",
        "outputId": "97fec862-f2a1-44fb-de58-24b5285cb20a"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-70-b004bd08d681>:3: DeprecationWarning: Call to deprecated `glove2word2vec` (KeyedVectors.load_word2vec_format(.., binary=False, no_header=True) loads GLoVE text vectors.).\n",
            "  glove2word2vec(embeddings_file, word2vec_output_file)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(400000, 100)"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load embeddings (may take a minute)\n",
        "glove = KeyedVectors.load_word2vec_format(word2vec_output_file, binary=False)"
      ],
      "metadata": {
        "id": "vPE5Smik21WF"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# (king - man) + woman = ?\n",
        "# king - man = ? -  woman\n",
        "glove.most_similar(positive=[\"woman\", \"king\"], negative=[\"man\"], topn=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vhk3waAq3che",
        "outputId": "843823e9-8211-48f4-bc17-3133490e1991"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('queen', 0.7698540687561035),\n",
              " ('monarch', 0.6843381524085999),\n",
              " ('throne', 0.6755736470222473),\n",
              " ('daughter', 0.6594556570053101),\n",
              " ('princess', 0.6520534157752991)]"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "glove.most_similar(positive=[\"woman\", \"boy\"], negative=[\"man\"], topn=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b-Kk8Z7K3zal",
        "outputId": "15588fb6-ffd1-44d4-ac65-7f2094559afa"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('girl', 0.9095936417579651),\n",
              " ('mother', 0.7666921019554138),\n",
              " ('child', 0.7420270442962646),\n",
              " ('pregnant', 0.7282999157905579),\n",
              " ('girls', 0.7268646359443665)]"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get nearest neighbors (excluding itself)\n",
        "glove.most_similar(positive=\"hey\", topn=5)"
      ],
      "metadata": {
        "id": "0wIXVSfb342R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05a16ff1-a438-43fb-9fc4-9fc5df2290f4"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('yeah', 0.8196864128112793),\n",
              " ('gonna', 0.7466485500335693),\n",
              " ('ok', 0.74472576379776),\n",
              " ('hello', 0.7171452045440674),\n",
              " ('`', 0.7170859575271606)]"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reduce dimensionality for plotting\n",
        "X = np.array([glove.get_vector(word) for word in glove.index_to_key])\n",
        "pca = PCA(n_components=2)\n",
        "pca_results = pca.fit_transform(X)"
      ],
      "metadata": {
        "id": "XN7yEO0zqogs"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize\n",
        "plot_embeddings(\n",
        "    words=[\"king\", \"queen\", \"man\", \"woman\"], embeddings=glove,\n",
        "    pca_results=pca_results)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "kP5bZCFcrjxE",
        "outputId": "0de92028-db27-406f-c740-96168a6bdca7"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Bias in embeddings\n",
        "glove.most_similar(positive=[\"woman\", \"doctor\"], negative=[\"man\"], topn=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A6BaNSPNvGGK",
        "outputId": "83f54561-1812-45d7-a87f-417ffa89c80e"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('nurse', 0.7735227942466736),\n",
              " ('physician', 0.7189430594444275),\n",
              " ('doctors', 0.6824328303337097),\n",
              " ('patient', 0.6750683188438416),\n",
              " ('dentist', 0.6726033091545105)]"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set device\n",
        "cuda = True\n",
        "device = torch.device(\"cuda\" if (\n",
        "    torch.cuda.is_available() and cuda) else \"cpu\")\n",
        "torch.set_default_tensor_type(\"torch.FloatTensor\")\n",
        "if device.type == \"cuda\":\n",
        "    torch.set_default_tensor_type(\"torch.cuda.FloatTensor\")\n",
        "print (device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nx5oLe-xworL",
        "outputId": "21c9d1c5-dc3a-46cb-eaf6-2bcb891cd1aa"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "49-lIYWvxkob"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}