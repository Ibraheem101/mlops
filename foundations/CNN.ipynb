{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ibraheem101/mlops/blob/main/foundations/CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "RenaIvkHnr0O"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import json\n",
        "import math\n",
        "import nltk\n",
        "import torch\n",
        "import random\n",
        "import itertools\n",
        "import collections\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "IseaNG-3ChD2"
      },
      "outputs": [],
      "source": [
        "seed = 1234"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "lLCdpMk62A7r"
      },
      "outputs": [],
      "source": [
        "def set_seeds(seed=1234):\n",
        "    \"\"\"Set seeds for reproducibility.\"\"\"\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed) # multi-GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "phmFCRHJCkBJ"
      },
      "outputs": [],
      "source": [
        "set_seeds(seed = seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OA2wWTnwCuOc",
        "outputId": "074009e5-fc98-4ce6-8ba1-8d564e982107"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ],
      "source": [
        "# Set device\n",
        "cuda = True\n",
        "device = torch.device(\"cuda\" if (\n",
        "    torch.cuda.is_available() and cuda) else \"cpu\")\n",
        "torch.set_default_tensor_type(\"torch.FloatTensor\")\n",
        "if device.type == \"cuda\":\n",
        "    torch.set_default_tensor_type(\"torch.cuda.FloatTensor\")\n",
        "print (device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "DWLzaiCvC2Lf",
        "outputId": "e9868b66-e72d-40fb-94b0-419e64fff7b5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               title  category\n",
              "0  Sharon Accepts Plan to Reduce Gaza Army Operat...     World\n",
              "1  Internet Key Battleground in Wildlife Crime Fight  Sci/Tech\n",
              "2          July Durable Good Orders Rise 1.7 Percent  Business\n",
              "3          Growing Signs of a Slowing on Wall Street  Business\n",
              "4                        The New Faces of Reality TV     World"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ec6ba91f-3336-4388-ad90-b573eb50dca5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Sharon Accepts Plan to Reduce Gaza Army Operat...</td>\n",
              "      <td>World</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Internet Key Battleground in Wildlife Crime Fight</td>\n",
              "      <td>Sci/Tech</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>July Durable Good Orders Rise 1.7 Percent</td>\n",
              "      <td>Business</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Growing Signs of a Slowing on Wall Street</td>\n",
              "      <td>Business</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The New Faces of Reality TV</td>\n",
              "      <td>World</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ec6ba91f-3336-4388-ad90-b573eb50dca5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ec6ba91f-3336-4388-ad90-b573eb50dca5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ec6ba91f-3336-4388-ad90-b573eb50dca5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# Load data\n",
        "url = \"https://raw.githubusercontent.com/GokuMohandas/Made-With-ML/main/datasets/news.csv\"\n",
        "df = pd.read_csv(url, header=0) # load\n",
        "df = df.sample(frac=1).reset_index(drop=True) # shuffle\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preprocessing"
      ],
      "metadata": {
        "id": "1LCEg9g9nfkL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import SnowballStemmer"
      ],
      "metadata": {
        "id": "UB-OgQzknhf6"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download(\"stopwords\")\n",
        "stop_words = stopwords.words(\"english\")\n",
        "print (stop_words[:5])\n",
        "sstm = SnowballStemmer('english')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xp45Ct3hoLdx",
        "outputId": "fe90ef1c-32e0-4496-8091-d01d1ecf77d5"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['i', 'me', 'my', 'myself', 'we']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(text, stopwords = stop_words):\n",
        "\n",
        "    # lowercasing\n",
        "    text = text.lower()\n",
        "\n",
        "    # Remove stopwords\n",
        "    pattern = re.compile(r\"\\b(\" + r\"|\".join(stopwords) + r\")\\b\\s*\")\n",
        "    text = pattern.sub(\"\", text)\n",
        "\n",
        "    # Remove words in parenthesis\n",
        "    text = re.sub(r\"\\([^)]*\\)\", \"\", text)\n",
        "\n",
        "    # Spacing and filters\n",
        "    text = re.sub(r\"([-;;.,!?<=>])\", r\" \\1 \", text)  # separate punctuation tied to words\n",
        "    text = re.sub(\"[^A-Za-z0-9]+\", \" \", text)  # remove non alphanumeric chars\n",
        "    text = re.sub(\" +\", \" \", text)  # remove multiple spaces\n",
        "    text = text.strip()\n",
        "\n",
        "    return text\n",
        "\n"
      ],
      "metadata": {
        "id": "IaC4kH7voklZ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample\n",
        "text = \"US and China take a potentially crucial step\"\n",
        "preprocess(text=text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "hnjEPIXeD2-y",
        "outputId": "68bf0176-e400-41ed-baf8-c0f63c0a267e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'us china take potentially crucial step'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply to dataframe\n",
        "preprocessed_df = df.copy()\n",
        "preprocessed_df.title = preprocessed_df.title.apply(preprocess)\n",
        "\n",
        "preprocessed_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "voN0THj2D6gT",
        "outputId": "76de7ec1-5f37-4cd0-bf17-c539f60c3c51"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               title  category\n",
              "0  sharon accepts plan reduce gaza army operation...     World\n",
              "1     internet key battleground wildlife crime fight  Sci/Tech\n",
              "2          july durable good orders rise 1 7 percent  Business\n",
              "3                  growing signs slowing wall street  Business\n",
              "4                               new faces reality tv     World"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0d29ff1c-16f1-4951-94f2-c61fcbb260dd\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>sharon accepts plan reduce gaza army operation...</td>\n",
              "      <td>World</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>internet key battleground wildlife crime fight</td>\n",
              "      <td>Sci/Tech</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>july durable good orders rise 1 7 percent</td>\n",
              "      <td>Business</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>growing signs slowing wall street</td>\n",
              "      <td>Business</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>new faces reality tv</td>\n",
              "      <td>World</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0d29ff1c-16f1-4951-94f2-c61fcbb260dd')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0d29ff1c-16f1-4951-94f2-c61fcbb260dd button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0d29ff1c-16f1-4951-94f2-c61fcbb260dd');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "8t0b4GYVHNov"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TRAIN_SIZE = 0.7\n",
        "VAL_SIZE = 0.15\n",
        "TEST_SIZE = 0.15"
      ],
      "metadata": {
        "id": "8aQ1FiyvjwM5"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_val_test_split(X, y, train_size):\n",
        "    \"\"\"Split dataset into data splits.\"\"\"\n",
        "    X_train, X_, y_train, y_ = train_test_split(X, y, train_size=TRAIN_SIZE, stratify=y)\n",
        "    X_val, X_test, y_val, y_test = train_test_split(X_, y_, train_size=0.5, stratify=y_)\n",
        "    return X_train, X_val, X_test, y_train, y_val, y_test"
      ],
      "metadata": {
        "id": "_N7KXIgmnLDA"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data\n",
        "X = preprocessed_df[\"title\"].values\n",
        "y = preprocessed_df[\"category\"].values"
      ],
      "metadata": {
        "id": "ip4GZVKsnPKH"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create data splits\n",
        "X_train, X_val, X_test, y_train, y_val, y_test = train_val_test_split(\n",
        "    X=X, y=y, train_size=TRAIN_SIZE)\n",
        "print (f\"X_train: {X_train.shape}, y_train: {y_train.shape}\")\n",
        "print (f\"X_val: {X_val.shape}, y_val: {y_val.shape}\")\n",
        "print (f\"X_test: {X_test.shape}, y_test: {y_test.shape}\")\n",
        "print (f\"Sample point: {X_train[10]} → {y_train[10]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ASmyKOcJnT0Z",
        "outputId": "51b7dc26-6989-4ba6-ba06-e1798e9879a8"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train: (84000,), y_train: (84000,)\n",
            "X_val: (18000,), y_val: (18000,)\n",
            "X_test: (18000,), y_test: (18000,)\n",
            "Sample point: air france klm sales rise 6 4 passenger increase → Business\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Label encoding"
      ],
      "metadata": {
        "id": "2GWWd2jfINq2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import OrderedDict"
      ],
      "metadata": {
        "id": "KbGtQIDImtSH"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LabelEncoder(object):\n",
        "    \"\"\"\n",
        "        Class to transform categorical labels into numerical values.\n",
        "\n",
        "        Attributes:\n",
        "            mapping (dict): A dictionary that maps labels to their corresponding numerical values.\n",
        "            reverse_mapping (dict): A dictionary that maps numerical values back to their original labels.\n",
        "            classes (list): A list of unique labels.\n",
        "\n",
        "        Methods:\n",
        "            fit(data): Fit the encoder to the given data by creating the mapping and reverse_mapping dictionaries.\n",
        "            encode(data): Encode the given data by replacing labels with their corresponding numerical values.\n",
        "            decode(data): Decode the given data by replacing numerical values with their original labels.\n",
        "            __len__(): Return the number of unique labels in the encoder.\n",
        "            __str__(): Return a string representation of the encoder.\n",
        "            save(fp): Save the encoder's mapping dictionary to a JSON file.\n",
        "            load(fp): Load a saved encoder from a JSON file.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    def __init__(self):\n",
        "        self.mapping = {}\n",
        "        self.reverse_mapping = {}\n",
        "        self.classes = []\n",
        "\n",
        "    def fit(self, data):\n",
        "        unique_labels = list(OrderedDict.fromkeys(data))\n",
        "        for value, label in enumerate(unique_labels):\n",
        "            self.mapping[label] = value\n",
        "            self.reverse_mapping[value] = label\n",
        "            self.classes.append(label)\n",
        "\n",
        "    def encode(self, data):\n",
        "        return [self.mapping[i] for i in data]\n",
        "\n",
        "    def decode(self, data):\n",
        "        return [self.reverse_mapping[j] for j in data]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.mapping)\n",
        "\n",
        "    def __str__(self):\n",
        "        return f\"<LabelEncoder(num_classes={len(self)})>\"\n",
        "\n",
        "    def save(self, fp):\n",
        "        with open(fp, \"w\") as fp:\n",
        "            contents = {'class_to_index': self.class_to_index}\n",
        "            json.dump(contents, fp, indent=4, sort_keys=False)\n",
        "\n",
        "    @classmethod\n",
        "    def load(cls, fp):\n",
        "        with open(fp, \"r\") as fp:\n",
        "            kwargs = json.load(fp=fp)\n",
        "        return cls(**kwargs)"
      ],
      "metadata": {
        "id": "yvyVfCc5GyX1"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode\n",
        "label_encoder = LabelEncoder()\n",
        "label_encoder.fit(y_train)\n",
        "num_classes = len(label_encoder)\n",
        "label_encoder.mapping"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W0DzbI-1IU6p",
        "outputId": "4d5ce67a-7f3f-4733-a9b9-622d790cfd65"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'World': 0, 'Sports': 1, 'Business': 2, 'Sci/Tech': 3}"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert labels to tokens\n",
        "print (f\"y_train[0]: {y_train[0]}\")\n",
        "y_train_enc = label_encoder.encode(y_train)\n",
        "y_val_enc = label_encoder.encode(y_val)\n",
        "y_test_enc = label_encoder.encode(y_test)\n",
        "print (f\"y_train[0]: {y_train_enc[0]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_8O1Fx8imbVV",
        "outputId": "46fa43cf-f0b4-4c00-991b-062ced02aa4d"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y_train[0]: World\n",
            "y_train[0]: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Class weights"
      ],
      "metadata": {
        "id": "5CdwYbzTq8E7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate class weights\n",
        "class_weights = {}\n",
        "total_samples = len(y_train_enc)\n",
        "num_classes = len(np.unique(y_train_enc))\n",
        "class_samples = np.bincount(y_train_enc)\n",
        "for i in range(num_classes):\n",
        "    class_weights[i] = total_samples / (num_classes * class_samples[i])\n",
        "\n",
        "print(f\"Class weights: {class_weights}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lbVxxygpqwgU",
        "outputId": "f50a106b-80f4-44d6-d573-e4354ebe93c7"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class weights: {0: 1.0, 1: 1.0, 2: 1.0, 3: 1.0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tokenizer"
      ],
      "metadata": {
        "id": "uodx3FmurUtg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "from more_itertools import take"
      ],
      "metadata": {
        "id": "ETWO5BB5rE-9"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Tokenizer(object):\n",
        "    def __init__(self, char_level, num_tokens=None,\n",
        "                 pad_token=\"<PAD>\", oov_token=\"<UNK>\",\n",
        "                 token_to_index=None):\n",
        "        self.char_level = char_level\n",
        "        self.separator = \"\" if self.char_level else \" \"\n",
        "        if num_tokens: num_tokens -= 2 # pad + unk tokens\n",
        "        self.num_tokens = num_tokens\n",
        "        self.pad_token = pad_token\n",
        "        self.oov_token = oov_token\n",
        "        if not token_to_index:\n",
        "            token_to_index = {pad_token: 0, oov_token: 1}\n",
        "        self.token_to_index = token_to_index\n",
        "        self.index_to_token = {v: k for k, v in self.token_to_index.items()}\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.token_to_index)\n",
        "\n",
        "    def __str__(self):\n",
        "        return f\"<Tokenizer(num_tokens={len(self)})>\"\n",
        "\n",
        "    def fit_on_texts(self, texts):\n",
        "        if not self.char_level:\n",
        "            texts = [text.split(\" \") for text in texts]\n",
        "        all_tokens = [token for text in texts for token in text]\n",
        "        counts = Counter(all_tokens).most_common(self.num_tokens)\n",
        "        self.min_token_freq = counts[-1][1]\n",
        "        for token, count in counts:\n",
        "            index = len(self)\n",
        "            self.token_to_index[token] = index\n",
        "            self.index_to_token[index] = token\n",
        "        return self\n",
        "\n",
        "    def texts_to_sequences(self, texts):\n",
        "        sequences = []\n",
        "        for text in texts:\n",
        "            if not self.char_level:\n",
        "                text = text.split(\" \")\n",
        "            sequence = []\n",
        "            for token in text:\n",
        "                sequence.append(self.token_to_index.get(\n",
        "                    token, self.token_to_index[self.oov_token]))\n",
        "            sequences.append(np.asarray(sequence))\n",
        "        return sequences\n",
        "\n",
        "    def sequences_to_texts(self, sequences):\n",
        "        texts = []\n",
        "        for sequence in sequences:\n",
        "            text = []\n",
        "            for index in sequence:\n",
        "                text.append(self.index_to_token.get(index, self.oov_token))\n",
        "            texts.append(self.separator.join([token for token in text]))\n",
        "        return texts\n",
        "\n",
        "    def save(self, fp):\n",
        "        with open(fp, \"w\") as fp:\n",
        "            contents = {\n",
        "                \"char_level\": self.char_level,\n",
        "                \"oov_token\": self.oov_token,\n",
        "                \"token_to_index\": self.token_to_index\n",
        "            }\n",
        "            json.dump(contents, fp, indent=4, sort_keys=False)\n",
        "\n",
        "    @classmethod\n",
        "    def load(cls, fp):\n",
        "        with open(fp, \"r\") as fp:\n",
        "            kwargs = json.load(fp=fp)\n",
        "        return cls(**kwargs)\n"
      ],
      "metadata": {
        "id": "0zEJPIHerYbe"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize\n",
        "tokenizer = Tokenizer(char_level=False, num_tokens=500)\n",
        "tokenizer.fit_on_texts(texts=X_train)\n",
        "VOCAB_SIZE = len(tokenizer)\n",
        "print (tokenizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DGO_iZtZrfei",
        "outputId": "c14eb18a-ed7a-4eef-8c47-682c1dc02512"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<Tokenizer(num_tokens=500)>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample of tokens\n",
        "print (take(5, tokenizer.token_to_index.items()))\n",
        "print (f\"least freq token's freq: {tokenizer.min_token_freq}\") # use this to adjust num_tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IFnc98serlvy",
        "outputId": "66827c03-557e-4aba-bce5-8077582767f3"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('<PAD>', 0), ('<UNK>', 1), ('39', 2), ('b', 3), ('gt', 4)]\n",
            "least freq token's freq: 166\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert texts to sequences of indices\n",
        "X_train_tok = tokenizer.texts_to_sequences(X_train)\n",
        "X_val_tok = tokenizer.texts_to_sequences(X_val)\n",
        "X_test_tok = tokenizer.texts_to_sequences(X_test)\n",
        "preprocessed_text = tokenizer.sequences_to_texts([X_train_tok[0]])[0]\n",
        "print (\"Text to indices:\\n\"\n",
        "    f\"  (preprocessed) → {preprocessed_text}\\n\"\n",
        "    f\"  (tokenized) → {X_train_tok[0]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rBcK_GVkrpH2",
        "outputId": "488adf93-60fc-40f1-d58b-b470e8b1dc22"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text to indices:\n",
            "  (preprocessed) → china <UNK> north korea nuclear talks\n",
            "  (tokenized) → [ 16   1 285 142 114  24]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### One-hot encoding"
      ],
      "metadata": {
        "id": "Ls2jFZCWtFvi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def one_hot_encode(features, num_classes):\n",
        "    num_samples = len(features)\n",
        "\n",
        "    # Create an array of zeros with shape (num_samples, num_classes)\n",
        "    one_hot_encoded = np.zeros((num_samples, num_classes))\n",
        "\n",
        "    # Set the corresponding element to 1 for each sample and class\n",
        "    for i, value in enumerate(features):\n",
        "        one_hot_encoded[i, value] = 1\n",
        "\n",
        "    return one_hot_encoded"
      ],
      "metadata": {
        "id": "wu8Ybr7Uryxk"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# One-hot encoding\n",
        "print (X_train_tok[0])\n",
        "print (len(X_train_tok[0]))\n",
        "cat = one_hot_encode(features=X_train_tok[0], num_classes=len(tokenizer))\n",
        "print (cat)\n",
        "print (cat.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rOWlv8xz1XXp",
        "outputId": "370222d9-881d-43e1-d918-207e0d6f1d21"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 16   1 285 142 114  24]\n",
            "6\n",
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 1. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n",
            "(6, 500)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert tokens to one-hot\n",
        "vocab_size = len(tokenizer)\n",
        "X_train_hot = [one_hot_encode(seq, num_classes=vocab_size) for seq in X_train_tok]\n",
        "X_val_hot = [one_hot_encode(seq, num_classes=vocab_size) for seq in X_val_tok]\n",
        "X_test_hot = [one_hot_encode(seq, num_classes=vocab_size) for seq in X_test_tok]"
      ],
      "metadata": {
        "id": "Zz7GT9EN1ppz"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Padding\n",
        "In the context of Natural Language Processing (NLP), padding refers to the process of adding special tokens or characters to sequences in order to make them of equal length. It is necessary because many machine learning models require input data of consistent dimensions.\n",
        "\n",
        "Padding is particularly relevant when working with sequential data, such as sentences or documents, where the length of the text varies. To ensure that all sequences have the same length, shorter sequences are padded with special tokens (such as <PAD>) to match the length of the longest sequence in the dataset."
      ],
      "metadata": {
        "id": "TDhbCtoQSUeG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(X_train_hot[0]), len(X_train_hot[1]), len(X_train_hot[9]) # Varying lengths"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3DGmlHDm7oXt",
        "outputId": "cf4c7afb-67ef-4180-a54b-8327d022ce72"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6, 5, 7)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def pad_sequences(sequences, max_seq_len=0):\n",
        "    \"\"\"Pad sequences to max length in sequence.\"\"\"\n",
        "    max_seq_len = max(max_seq_len, max(len(sequence) for sequence in sequences))\n",
        "    num_classes = sequences[0].shape[-1]\n",
        "    padded_sequences = np.zeros((len(sequences), max_seq_len, num_classes))\n",
        "    for i, sequence in enumerate(sequences):\n",
        "        padded_sequences[i][:len(sequence)] = sequence\n",
        "    return padded_sequences"
      ],
      "metadata": {
        "id": "S8tUh6M_RZBH"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<details>\n",
        "  <summary>Padding with zero</summary>\n",
        "\n",
        "  Padding with 0 is a common practice and is generally a good idea in many cases. Here are a few reasons why padding with 0 is commonly used:\n",
        "\n",
        "Compatibility: Padding with 0 is compatible with many machine learning frameworks and libraries. Most frameworks, including PyTorch and TensorFlow, handle 0-padding efficiently and have built-in functions to handle it.\n",
        "\n",
        "Zero-padding doesn't introduce noise: When padding with zeros, you are essentially adding neutral values that do not carry any meaning or bias. This ensures that the padding does not introduce any unwanted noise or affect the data distribution.\n",
        "\n",
        "Easy handling of variable-length sequences: Padding with 0 allows you to convert variable-length sequences into fixed-length sequences, which is often required for batch processing and model training. It simplifies the handling of sequences by ensuring consistent dimensions.\n",
        "\n",
        "Memory efficiency: Padding with 0 doesn't require additional memory or storage for the padding values. Zeros are already present in the memory and can be easily allocated, making it memory-efficient.\n",
        "\n",
        "However, it's important to note that the choice of padding value may depend on the specific problem and the data being used. In some cases, other padding values such as a specific value outside the range of the data or a special token may be more appropriate. It's always recommended to consider the characteristics of your data and the requirements of your model when deciding on the padding strategy.\n",
        "\n",
        "</details>"
      ],
      "metadata": {
        "id": "XcH8QJWdVzPb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 3D sequences\n",
        "print (X_train_hot[0].shape, X_train_hot[1].shape, X_train_hot[2].shape)\n",
        "padded = pad_sequences(X_train_hot[0:3])\n",
        "print (padded.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EuRXwOqCVxJL",
        "outputId": "13216965-89d7-47b7-c989-754df9915c38"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(6, 500) (5, 500) (6, 500)\n",
            "(3, 6, 500)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset"
      ],
      "metadata": {
        "id": "AYG3zUJ8fbOW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filter_size = 1 # unigram"
      ],
      "metadata": {
        "id": "5RBywkRHfkjU"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Dataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, X, y, max_filter_size):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "        self.max_filter_size = max_filter_size\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.y)\n",
        "\n",
        "    def __str__(self):\n",
        "        return f\"<Dataset(N={len(self)})>\"\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        X = self.X[index]\n",
        "        y = self.y[index]\n",
        "        return [X, y]\n",
        "\n",
        "    def collate_fn(self, batch):\n",
        "        \"\"\"Processing on a batch.\"\"\"\n",
        "        # Get inputs\n",
        "        batch = np.array(batch)\n",
        "        X = batch[:, 0]\n",
        "        y = batch[:, 1]\n",
        "\n",
        "        # Pad sequences\n",
        "        X = pad_sequences(X, max_seq_len=self.max_filter_size)\n",
        "\n",
        "        # Cast\n",
        "        X = torch.FloatTensor(X.astype(np.int32))\n",
        "        y = torch.LongTensor(y.astype(np.int32))\n",
        "\n",
        "        return X, y\n",
        "\n",
        "    def create_dataloader(self, batch_size, shuffle=False, drop_last=False):\n",
        "        return torch.utils.data.DataLoader(\n",
        "            dataset=self, batch_size=batch_size, collate_fn=self.collate_fn,\n",
        "            shuffle=shuffle, drop_last=drop_last, pin_memory=True)\n"
      ],
      "metadata": {
        "id": "dOyVNPh-YngP"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create datasets\n",
        "train_dataset = Dataset(X=X_train_hot, y=y_train_enc, max_filter_size=filter_size)\n",
        "val_dataset = Dataset(X=X_val_hot, y=y_val_enc, max_filter_size=filter_size)\n",
        "test_dataset = Dataset(X=X_test_hot, y=y_test_enc, max_filter_size=filter_size)\n",
        "print (\"Datasets:\\n\"\n",
        "    f\"  Train dataset:{train_dataset.__str__()}\\n\"\n",
        "    f\"  Val dataset: {val_dataset.__str__()}\\n\"\n",
        "    f\"  Test dataset: {test_dataset.__str__()}\\n\"\n",
        "    \"Sample point:\\n\"\n",
        "    f\"  X: {train_dataset[0][0]}\\n\"\n",
        "    f\"  y: {train_dataset[0][1]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gI_NDLDgfnrf",
        "outputId": "6f9ab500-6bc8-40b5-f3f0-d3ee7f2ba9ff"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Datasets:\n",
            "  Train dataset:<Dataset(N=84000)>\n",
            "  Val dataset: <Dataset(N=18000)>\n",
            "  Test dataset: <Dataset(N=18000)>\n",
            "Sample point:\n",
            "  X: [[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 1. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n",
            "  y: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mini batch gradient descent with dataloader\n",
        "batch_size = 64\n",
        "train_dataloader = train_dataset.create_dataloader(batch_size=batch_size)\n",
        "val_dataloader = val_dataset.create_dataloader(batch_size=batch_size)\n",
        "test_dataloader = test_dataset.create_dataloader(batch_size=batch_size)\n",
        "batch_X, batch_y = next(iter(test_dataloader))\n",
        "print (\"Sample batch:\\n\"\n",
        "    f\"  X: {list(batch_X.size())}\\n\"\n",
        "    f\"  y: {list(batch_y.size())}\\n\"\n",
        "    \"Sample point:\\n\"\n",
        "    f\"  X: {batch_X[0]}\\n\"\n",
        "    f\"  y: {batch_y[0]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q1jrOmYSgz83",
        "outputId": "5ae49f81-2542-4ca2-c437-f6c226bd9095"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample batch:\n",
            "  X: [64, 14, 500]\n",
            "  y: [64]\n",
            "Sample point:\n",
            "  X: tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
            "  y: 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-34-d8e138c3ed26>:21: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  batch = np.array(batch)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CNN"
      ],
      "metadata": {
        "id": "f9OG6CuM4tVN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_FILTERS = 50\n",
        "HIDDEN_DIM = 100\n",
        "DROPOUT_P = 0.1"
      ],
      "metadata": {
        "id": "GNI4VFyX-Cbk"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self, vocab_size, num_filters, filter_size,\n",
        "                 hidden_dim, dropout_p, num_classes):\n",
        "        super(CNN, self).__init__()\n",
        "\n",
        "        # Convolutional filters\n",
        "        self.filter_size = filter_size\n",
        "        self.conv = nn.Conv1d(\n",
        "            in_channels=vocab_size, out_channels=num_filters,\n",
        "            kernel_size=filter_size, stride=1, padding=0, padding_mode=\"zeros\")\n",
        "        self.batch_norm = nn.BatchNorm1d(num_features=num_filters)\n",
        "\n",
        "        # FC layers\n",
        "        self.fc1 = nn.Linear(num_filters, hidden_dim)\n",
        "        self.dropout = nn.Dropout(dropout_p)\n",
        "        self.fc2 = nn.Linear(hidden_dim, num_classes)\n",
        "\n",
        "    def forward(self, inputs, channel_first=False,):\n",
        "\n",
        "        # Rearrange input so num_channels is in dim 1 (N, C, L)\n",
        "        x_in, = inputs\n",
        "        if not channel_first:\n",
        "            x_in = x_in.transpose(1, 2)\n",
        "\n",
        "        # Padding for `SAME` padding\n",
        "        max_seq_len = x_in.shape[2]\n",
        "        padding_left = int((self.conv.stride[0]*(max_seq_len-1) - max_seq_len + self.filter_size)/2)\n",
        "        padding_right = int(math.ceil((self.conv.stride[0]*(max_seq_len-1) - max_seq_len + self.filter_size)/2))\n",
        "\n",
        "        # Conv outputs\n",
        "        z = self.conv(F.pad(x_in, (padding_left, padding_right)))\n",
        "        z = F.max_pool1d(z, z.size(2)).squeeze(2)\n",
        "\n",
        "        # FC layer\n",
        "        z = self.fc1(z)\n",
        "        z = self.dropout(z)\n",
        "        z = self.fc2(z)\n",
        "        return z\n"
      ],
      "metadata": {
        "id": "5dkm4BIXgUyY"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code defines a CNN (Convolutional Neural Network) model for text classification. Here's a breakdown of the key components:\n",
        "\n",
        "Convolutional Filters: The model uses a 1D convolutional layer (nn.Conv1d) to extract local features from the input text. The convolutional layer has vocab_size input channels, num_filters output channels, and a kernel size of filter_size. It applies convolutional filters over the input text to capture different patterns.\n",
        "\n",
        "Batch Normalization: After the convolutional layer, the model applies batch normalization (nn.BatchNorm1d) to normalize the output activations. Batch normalization helps stabilize and speed up the training process by normalizing the activations across the mini-batches.\n",
        "\n",
        "Fully Connected Layers: The model has two fully connected (FC) layers (nn.Linear) for further processing of the extracted features. The first FC layer takes the output of the convolutional layer and transforms it to a higher-dimensional space represented by hidden_dim. The second FC layer maps the hidden representation to the num_classes output classes.\n",
        "\n",
        "Padding: To handle different input sequence lengths and maintain spatial resolution, the input sequences are padded with appropriate padding sizes. The padding_left and padding_right values are calculated based on the convolution stride and filter size to ensure \"SAME\" padding, where the output feature maps have the same size as the input.\n",
        "\n",
        "Pooling: After the convolutional layer, the model applies max pooling (F.max_pool1d) to reduce the spatial dimension of the feature maps. This operation extracts the most important features and reduces the output size.\n",
        "\n",
        "Dropout: Dropout regularization (nn.Dropout) is applied between the two FC layers. Dropout randomly sets a fraction of the input units to zero during training, which helps prevent overfitting and improves generalization.\n",
        "\n",
        "Forward Pass: The forward method defines the forward pass of the model. It takes input inputs and applies the defined operations sequentially. The input inputs should be a tuple containing the input tensors. The method returns the output logits z, which represent the predicted class probabilities for each input."
      ],
      "metadata": {
        "id": "vU3Xl5EigoF0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The line x_in = x_in.transpose(1, 2) is used to transpose the dimensions of the input tensor x_in if channel_first is set to False.\n",
        "\n",
        "By default, PyTorch assumes that the input tensor has dimensions in the order of (batch_size, num_channels, sequence_length) (also known as channel-first format). However, in some cases, the input data may be provided in a different format, such as (batch_size, sequence_length, num_channels) (channel-last format)."
      ],
      "metadata": {
        "id": "RstJFV9PgfbB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize model\n",
        "model = CNN(vocab_size=VOCAB_SIZE, num_filters=NUM_FILTERS, filter_size=filter_size,\n",
        "            hidden_dim=HIDDEN_DIM, dropout_p=DROPOUT_P, num_classes=num_classes)\n",
        "model = model.to(device) # set device\n",
        "print (model.named_parameters)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "30akwjLOgZGI",
        "outputId": "86327edf-476b-41e1-ed78-53f7e71ed3ce"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<bound method Module.named_parameters of CNN(\n",
            "  (conv): Conv1d(500, 50, kernel_size=(1,), stride=(1,))\n",
            "  (batch_norm): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (fc1): Linear(in_features=50, out_features=100, bias=True)\n",
            "  (dropout): Dropout(p=0.1, inplace=False)\n",
            "  (fc2): Linear(in_features=100, out_features=4, bias=True)\n",
            ")>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training"
      ],
      "metadata": {
        "id": "IK8-AIJTjlwy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim import Adam"
      ],
      "metadata": {
        "id": "XsqxKjuvjL61"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 1e-3\n",
        "patience = 5\n",
        "epochs = 10"
      ],
      "metadata": {
        "id": "ro2-c_YVjknO"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Trainer(object):\n",
        "    def __init__(self, model, device, loss_fn=None, optimizer=None, scheduler=None):\n",
        "\n",
        "        # Set params\n",
        "        self.model = model\n",
        "        self.device = device\n",
        "        self.loss_fn = loss_fn\n",
        "        self.optimizer = optimizer\n",
        "        self.scheduler = scheduler\n",
        "\n",
        "    def train_step(self, dataloader):\n",
        "        \"\"\"Train step.\"\"\"\n",
        "        # Set model to train mode\n",
        "        self.model.train()\n",
        "        loss = 0.0\n",
        "\n",
        "        # Iterate over train batches\n",
        "        for i, batch in enumerate(dataloader):\n",
        "\n",
        "            # Step\n",
        "            batch = [item.to(self.device) for item in batch]  # Set device\n",
        "            inputs, targets = batch[:-1], batch[-1]\n",
        "            self.optimizer.zero_grad()  # Reset gradients\n",
        "            z = self.model(inputs)  # Forward pass\n",
        "            J = self.loss_fn(z, targets)  # Define loss\n",
        "            J.backward()  # Backward pass\n",
        "            self.optimizer.step()  # Update weights\n",
        "\n",
        "            # Cumulative Metrics\n",
        "            loss += (J.detach().item() - loss) / (i + 1)\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def eval_step(self, dataloader):\n",
        "        \"\"\"Validation or test step.\"\"\"\n",
        "        # Set model to eval mode\n",
        "        self.model.eval()\n",
        "        loss = 0.0\n",
        "        y_trues, y_probs = [], []\n",
        "\n",
        "        # Iterate over val batches\n",
        "        with torch.inference_mode():\n",
        "            for i, batch in enumerate(dataloader):\n",
        "\n",
        "                # Step\n",
        "                batch = [item.to(self.device) for item in batch]  # Set device\n",
        "                inputs, y_true = batch[:-1], batch[-1]\n",
        "                z = self.model(inputs)  # Forward pass\n",
        "                J = self.loss_fn(z, y_true).item()\n",
        "\n",
        "                # Cumulative Metrics\n",
        "                loss += (J - loss) / (i + 1)\n",
        "\n",
        "                # Store outputs\n",
        "                y_prob = F.softmax(z).cpu().numpy()\n",
        "                y_probs.extend(y_prob)\n",
        "                y_trues.extend(y_true.cpu().numpy())\n",
        "\n",
        "        return loss, np.vstack(y_trues), np.vstack(y_probs)\n",
        "\n",
        "    def predict_step(self, dataloader):\n",
        "        \"\"\"Prediction step.\"\"\"\n",
        "        # Set model to eval mode\n",
        "        self.model.eval()\n",
        "        y_probs = []\n",
        "\n",
        "        # Iterate over val batches\n",
        "        with torch.inference_mode():\n",
        "            for i, batch in enumerate(dataloader):\n",
        "\n",
        "                # Forward pass w/ inputs\n",
        "                inputs, targets = batch[:-1], batch[-1]\n",
        "                z = self.model(inputs)\n",
        "\n",
        "                # Store outputs\n",
        "                y_prob = F.softmax(z).cpu().numpy()\n",
        "                y_probs.extend(y_prob)\n",
        "\n",
        "        return np.vstack(y_probs)\n",
        "\n",
        "    def train(self, num_epochs, patience, train_dataloader, val_dataloader):\n",
        "        best_val_loss = np.inf\n",
        "        for epoch in range(num_epochs):\n",
        "            # Steps\n",
        "            train_loss = self.train_step(dataloader=train_dataloader)\n",
        "            val_loss, _, _ = self.eval_step(dataloader=val_dataloader)\n",
        "            self.scheduler.step(val_loss)\n",
        "\n",
        "            # Early stopping\n",
        "            if val_loss < best_val_loss:\n",
        "                best_val_loss = val_loss\n",
        "                best_model = self.model\n",
        "                _patience = patience  # reset _patience\n",
        "            else:\n",
        "                _patience -= 1\n",
        "            if not _patience:  # 0\n",
        "                print(\"Stopping early!\")\n",
        "                break\n",
        "\n",
        "            # Logging\n",
        "            print(\n",
        "                f\"Epoch: {epoch+1} | \"\n",
        "                f\"train_loss: {train_loss:.5f}, \"\n",
        "                f\"val_loss: {val_loss:.5f}, \"\n",
        "                f\"lr: {self.optimizer.param_groups[0]['lr']:.2E}, \"\n",
        "                f\"_patience: {_patience}\"\n",
        "            )\n",
        "        return best_model\n"
      ],
      "metadata": {
        "id": "pko0Yhdyjwp9"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Loss\n",
        "class_weights_tensor = torch.Tensor(list(class_weights.values())).to(device)\n",
        "loss_fn = nn.CrossEntropyLoss(weight=class_weights_tensor)"
      ],
      "metadata": {
        "id": "6tWKoHKQj0-q"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define optimizer & scheduler\n",
        "optimizer = Adam(model.parameters(), lr=lr)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    optimizer, mode=\"min\", factor=0.1, patience=3)"
      ],
      "metadata": {
        "id": "by4lBEJxlbBt"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Trainer module\n",
        "trainer = Trainer(\n",
        "    model=model, device=device, loss_fn=loss_fn,\n",
        "    optimizer=optimizer, scheduler=scheduler)"
      ],
      "metadata": {
        "id": "WqBfmFGDmSXu"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train\n",
        "best_model = trainer.train(\n",
        "    epochs, patience, train_dataloader, val_dataloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KIjo5aO6mUnQ",
        "outputId": "82e5e535-0e26-4d35-9e06-a7bb88c0f5a3"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-34-d8e138c3ed26>:21: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  batch = np.array(batch)\n",
            "<ipython-input-45-edcac1f51824>:55: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  y_prob = F.softmax(z).cpu().numpy()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 | train_loss: 0.87051, val_loss: 0.78786, lr: 1.00E-03, _patience: 5\n",
            "Epoch: 2 | train_loss: 0.78283, val_loss: 0.78516, lr: 1.00E-03, _patience: 5\n",
            "Epoch: 3 | train_loss: 0.77612, val_loss: 0.78323, lr: 1.00E-03, _patience: 5\n",
            "Epoch: 4 | train_loss: 0.77166, val_loss: 0.78147, lr: 1.00E-03, _patience: 5\n",
            "Epoch: 5 | train_loss: 0.76821, val_loss: 0.78127, lr: 1.00E-03, _patience: 5\n",
            "Epoch: 6 | train_loss: 0.76566, val_loss: 0.78067, lr: 1.00E-03, _patience: 5\n",
            "Epoch: 7 | train_loss: 0.76350, val_loss: 0.78052, lr: 1.00E-03, _patience: 5\n",
            "Epoch: 8 | train_loss: 0.76140, val_loss: 0.77999, lr: 1.00E-03, _patience: 5\n",
            "Epoch: 9 | train_loss: 0.75998, val_loss: 0.78012, lr: 1.00E-03, _patience: 4\n",
            "Epoch: 10 | train_loss: 0.75859, val_loss: 0.78002, lr: 1.00E-03, _patience: 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MmzjOwMDmYUH"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNEPLHSTTsjrWF+k7e2DOE1",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}